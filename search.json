[
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "practice1",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n2\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n3\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n4\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     145 non-null    float64\n 11  Nov     145 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     144 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     145 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.6 KB\n\n\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。\n\n\n\n绘制温度和时间折线图\n\ndf = df.set_index(\"Year\")\ndf.head()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.59\n1.69\n1.66\n1.39\n1.27\n1.14\n1.10\n1.12\n1.19\n1.21\n1.58\n1.18\n1.34\n1.36\n1.56\n1.44\n1.12\n1.33\n\n\n2021\n1.25\n0.96\n1.20\n1.13\n1.05\n1.21\n1.07\n1.02\n1.05\n1.29\n1.29\n1.17\n1.14\n1.14\n1.13\n1.13\n1.10\n1.21\n\n\n2022\n1.24\n1.16\n1.41\n1.09\n1.02\n1.13\n1.06\n1.17\n1.15\n1.31\n1.09\n1.06\n1.16\n1.17\n1.19\n1.17\n1.12\n1.19\n\n\n2023\n1.29\n1.29\n1.64\n1.01\n1.13\n1.19\n1.44\n1.57\n1.67\n1.88\n1.97\n1.85\n1.50\n1.43\n1.22\n1.26\n1.40\n1.84\n\n\n2024\n1.67\n1.93\n1.77\n1.79\n1.44\n1.54\n1.42\n1.42\n1.58\n1.72\n1.90\nNaN\nNaN\n1.67\n1.82\n1.67\n1.46\n1.73\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ndf[\"Feb\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。\n\n\n\n制作年气温异常的折线图\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n从上图的气温可以看出气温随着年份的增长而增长，尤其是近年来呈指数型增长，因此政府需要关注气候变化。\n\n\n\n创建直方图和频率表\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n\n\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.22\n      Aug   -0.25\n1881  Jun   -0.34\n      Jul    0.09\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\n\n\n\n\n\n\n\n\n\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.18\n\n\n3\n1951\nApr\n0.06\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.10\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.21\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is -0.1\nThe hot threshold of 70.0% is 0.1\n\n\n根据上述的表格信息和结果输出，我们在这段时间内更频繁地经历更热的天气。\n\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.80\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under -0.1 is 1.94%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 0.1 is 84.72%\n\n\n\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nSeason\nValues\nPeriod\n\n\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.43\n1981—2010\n\n\n448\n1992\nMAM\n0.29\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n453\n1993\nJJA\n0.12\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nSeason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.025862\n0.057489\n\n\n1951—1980\n-0.002000\n0.050548\n\n\n1981—2010\n0.523333\n0.078975\n\n\nJJA\n1921—1950\n-0.053448\n0.021423\n\n\n1951—1980\n0.000000\n0.014697\n\n\n1981—2010\n0.400000\n0.067524\n\n\nMAM\n1921—1950\n-0.041034\n0.031302\n\n\n1951—1980\n0.000333\n0.025245\n\n\n1981—2010\n0.509333\n0.075737\n\n\nSON\n1921—1950\n0.083448\n0.027473\n\n\n1951—1980\n-0.001333\n0.026205\n\n\n1981—2010\n0.429000\n0.111127\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n              1951—1980 average\n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1880\n            \n          \n        \n        \n          \n          \n          \n            \n              1900\n            \n          \n        \n        \n          \n          \n          \n            \n              1920\n            \n          \n        \n        \n          \n          \n          \n            \n              1940\n            \n          \n        \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2020\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -1.0\n            \n          \n        \n        \n          \n            \n              -0.5\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.5\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n        \n          \n            \n              1.5\n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in\n      \n      \n        in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            Season\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                DJF\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\n\n\n\ndf_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.0\n            \n          \n        \n        \n          \n          \n          \n            \n              0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.4\n            \n          \n        \n        \n          \n          \n          \n            \n              0.6\n            \n          \n        \n        \n          \n          \n          \n            \n              0.8\n            \n          \n        \n        \n          \n          \n          \n            \n              1.0\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              320\n            \n          \n        \n        \n          \n            \n              340\n            \n          \n        \n        \n          \n            \n              360\n            \n          \n        \n        \n          \n            \n              380\n            \n          \n        \n        \n          \n            \n              400\n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.000000\n0.915419\n\n\nTrend\n0.915419\n1.000000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1970\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              1990\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2010\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.2\n            \n          \n        \n        \n          \n            \n              0.4\n            \n          \n        \n        \n          \n            \n              0.6\n            \n          \n        \n        \n          \n            \n              0.8\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n\n\n\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。\n\nSource: 演练1.1"
  },
  {
    "objectID": "practice.html#演练1.1",
    "href": "practice.html#演练1.1",
    "title": "practice1",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\n\n\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n2\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n3\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n4\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     145 non-null    float64\n 11  Nov     145 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     144 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     145 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.6 KB\n\n\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。"
  },
  {
    "objectID": "practice.html#演练1.2",
    "href": "practice.html#演练1.2",
    "title": "practice1",
    "section": "",
    "text": "绘制温度和时间折线图\n\ndf = df.set_index(\"Year\")\ndf.head()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.59\n1.69\n1.66\n1.39\n1.27\n1.14\n1.10\n1.12\n1.19\n1.21\n1.58\n1.18\n1.34\n1.36\n1.56\n1.44\n1.12\n1.33\n\n\n2021\n1.25\n0.96\n1.20\n1.13\n1.05\n1.21\n1.07\n1.02\n1.05\n1.29\n1.29\n1.17\n1.14\n1.14\n1.13\n1.13\n1.10\n1.21\n\n\n2022\n1.24\n1.16\n1.41\n1.09\n1.02\n1.13\n1.06\n1.17\n1.15\n1.31\n1.09\n1.06\n1.16\n1.17\n1.19\n1.17\n1.12\n1.19\n\n\n2023\n1.29\n1.29\n1.64\n1.01\n1.13\n1.19\n1.44\n1.57\n1.67\n1.88\n1.97\n1.85\n1.50\n1.43\n1.22\n1.26\n1.40\n1.84\n\n\n2024\n1.67\n1.93\n1.77\n1.79\n1.44\n1.54\n1.42\n1.42\n1.58\n1.72\n1.90\nNaN\nNaN\n1.67\n1.82\n1.67\n1.46\n1.73\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ndf[\"Feb\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。"
  },
  {
    "objectID": "practice.html#演练1.3",
    "href": "practice.html#演练1.3",
    "title": "practice1",
    "section": "",
    "text": "制作年气温异常的折线图\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n从上图的气温可以看出气温随着年份的增长而增长，尤其是近年来呈指数型增长，因此政府需要关注气候变化。"
  },
  {
    "objectID": "practice.html#演练1.4",
    "href": "practice.html#演练1.4",
    "title": "practice1",
    "section": "",
    "text": "创建直方图和频率表\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n\n\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.22\n      Aug   -0.25\n1881  Jun   -0.34\n      Jul    0.09\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();"
  },
  {
    "objectID": "practice.html#演练1.5",
    "href": "practice.html#演练1.5",
    "title": "practice1",
    "section": "",
    "text": "temp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.18\n\n\n3\n1951\nApr\n0.06\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.10\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.21\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is -0.1\nThe hot threshold of 70.0% is 0.1\n\n\n根据上述的表格信息和结果输出，我们在这段时间内更频繁地经历更热的天气。"
  },
  {
    "objectID": "practice.html#演练1.6",
    "href": "practice.html#演练1.6",
    "title": "practice1",
    "section": "",
    "text": "# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.80\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under -0.1 is 1.94%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 0.1 is 84.72%"
  },
  {
    "objectID": "practice.html#演练1.7",
    "href": "practice.html#演练1.7",
    "title": "practice1",
    "section": "",
    "text": "temp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nSeason\nValues\nPeriod\n\n\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.43\n1981—2010\n\n\n448\n1992\nMAM\n0.29\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n453\n1993\nJJA\n0.12\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nSeason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.025862\n0.057489\n\n\n1951—1980\n-0.002000\n0.050548\n\n\n1981—2010\n0.523333\n0.078975\n\n\nJJA\n1921—1950\n-0.053448\n0.021423\n\n\n1951—1980\n0.000000\n0.014697\n\n\n1981—2010\n0.400000\n0.067524\n\n\nMAM\n1921—1950\n-0.041034\n0.031302\n\n\n1951—1980\n0.000333\n0.025245\n\n\n1981—2010\n0.509333\n0.075737\n\n\nSON\n1921—1950\n0.083448\n0.027473\n\n\n1951—1980\n-0.001333\n0.026205\n\n\n1981—2010\n0.429000\n0.111127\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n              1951—1980 average\n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1880\n            \n          \n        \n        \n          \n          \n          \n            \n              1900\n            \n          \n        \n        \n          \n          \n          \n            \n              1920\n            \n          \n        \n        \n          \n          \n          \n            \n              1940\n            \n          \n        \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2020\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -1.0\n            \n          \n        \n        \n          \n            \n              -0.5\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.5\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n        \n          \n            \n              1.5\n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in\n      \n      \n        in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            Season\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                DJF"
  },
  {
    "objectID": "practice.html#演练1.8",
    "href": "practice.html#演练1.8",
    "title": "practice1",
    "section": "",
    "text": "df_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.0\n            \n          \n        \n        \n          \n          \n          \n            \n              0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.4\n            \n          \n        \n        \n          \n          \n          \n            \n              0.6\n            \n          \n        \n        \n          \n          \n          \n            \n              0.8\n            \n          \n        \n        \n          \n          \n          \n            \n              1.0\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              320\n            \n          \n        \n        \n          \n            \n              340\n            \n          \n        \n        \n          \n            \n              360\n            \n          \n        \n        \n          \n            \n              380\n            \n          \n        \n        \n          \n            \n              400\n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.000000\n0.915419\n\n\nTrend\n0.915419\n1.000000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1970\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              1990\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2010\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.2\n            \n          \n        \n        \n          \n            \n              0.4\n            \n          \n        \n        \n          \n            \n              0.6\n            \n          \n        \n        \n          \n            \n              0.8\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n\n\n\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "practice.html#演练2.1",
    "href": "practice.html#演练2.1",
    "title": "practice1",
    "section": "演练2.1",
    "text": "演练2.1\n\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\n\n\n\n\n\n\n\n\nCopenhagen\nDniprop\nMinsk\n\n\n\n\n0\n14.1\n11.0\n12.8\n\n\n1\n14.1\n12.6\n12.3\n\n\n2\n13.7\n12.1\n12.6\n\n\n3\n12.9\n11.2\n12.3\n\n\n4\n12.3\n11.3\n11.8\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");"
  },
  {
    "objectID": "practice.html#演练2.2",
    "href": "practice.html#演练2.2",
    "title": "practice1",
    "section": "演练2.2",
    "text": "演练2.2\n\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")"
  },
  {
    "objectID": "practice.html#演练2.3",
    "href": "practice.html#演练2.3",
    "title": "practice1",
    "section": "演练2.3",
    "text": "演练2.3\n\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();"
  },
  {
    "objectID": "practice.html#演练2.4",
    "href": "practice.html#演练2.4",
    "title": "practice1",
    "section": "演练2.4",
    "text": "演练2.4\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);"
  },
  {
    "objectID": "practice.html#演练2.5",
    "href": "practice.html#演练2.5",
    "title": "practice1",
    "section": "演练2.5",
    "text": "演练2.5\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();"
  },
  {
    "objectID": "practice.html#演练2.6",
    "href": "practice.html#演练2.6",
    "title": "practice1",
    "section": "演练2.6",
    "text": "演练2.6\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\n\n\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();"
  },
  {
    "objectID": "practice.html#演练2.7",
    "href": "practice.html#演练2.7",
    "title": "practice1",
    "section": "演练2.7",
    "text": "演练2.7\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87"
  },
  {
    "objectID": "practice.html#演练2.8",
    "href": "practice.html#演练2.8",
    "title": "practice1",
    "section": "演练2.8",
    "text": "演练2.8\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082"
  },
  {
    "objectID": "practice/pratice3_3.html",
    "href": "practice/pratice3_3.html",
    "title": "",
    "section": "",
    "text": "import requests\nfrom bs4 import BeautifulSoup\nimport csv\n\n# 提取电影名称、描述、评分和评价人数\nmovies = []\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\nfor page in range(10):\n    # 定义请求的 URL 和 headers\n    url = f\"https://movie.douban.com/top250?start={25 * page}&filter=\"\n    \n    # 发送 GET 请求\n    response = requests.get(url, headers=headers)\n    response.encoding = 'utf-8'  # 设置编码方式\n    html_content = response.text  # 获取网页的 HTML 内容\n    \n    # 使用 Beautiful Soup 解析 HTML\n    soup = BeautifulSoup(html_content, 'html.parser')\n    \n    \n    for item in soup.find_all('div', class_='item'):\n        title = item.find('span', class_='title').get_text()  # 电影名称\n        description = item.find('span', class_='inq')  # 电影描述\n        rating = item.find('span', class_='rating_num').get_text()  # 评分\n        votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n        \n        # 如果没有描述，将其置为空字符串\n        if description:\n            description = description.get_text()\n        else:\n            description = ''\n        \n        movie = {\n            \"title\": title,\n            \"description\": description,\n            \"rating\": rating,\n            \"votes\": votes.replace('人评价', '').strip()\n        }\n        movies.append(movie)\n    break\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\n\n数据已成功保存到 douban_top250.csv\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei']\n\n# 读取CSV数据\nfile_path = 'douban_top250.csv'  # 确保路径正确\ndata = pd.read_csv(file_path)\n\n# 根据评分展示Top 10电影\ntop10_rating = data.nlargest(10, 'rating')  # 取评分最高的前10部电影\n\nplt.figure(figsize=(10, 6))\nplt.barh(top10_rating['title'], top10_rating['rating'], color='skyblue')\nplt.xlabel('Rating')\nplt.title('Top 10 Movies by Rating')\nplt.gca().invert_yaxis()  # 翻转Y轴，使排名靠前的电影显示在顶部\nplt.show()\n\n\n\n\n\n\n\n\n\n# 评分与投票数的散点图\nplt.figure(figsize=(10, 6))\nplt.scatter(data['votes'], data['rating'], alpha=0.7, color='coral')\nplt.title('Relationship between Votes and Rating')\nplt.xlabel('Number of Votes')\nplt.ylabel('Rating')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "practice/pratice3_1.html",
    "href": "practice/pratice3_1.html",
    "title": "",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\n\n\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\n\n\n\n\n\n\n\n\nrownames\nname\nyear\nmonth\nday\nhour\nlat\nlong\nstatus\ncategory\nwind\npressure\ntropicalstorm_force_diameter\nhurricane_force_diameter\n\n\n\n\n0\n1\nAmy\n1975\n6\n27\n0\n27.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n1\n2\nAmy\n1975\n6\n27\n6\n28.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n2\n3\nAmy\n1975\n6\n27\n12\n29.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n3\n4\nAmy\n1975\n6\n27\n18\n30.5\n-79.0\ntropical depression\nNaN\n25\n1013\nNaN\nNaN\n\n\n4\n5\nAmy\n1975\n6\n28\n0\n31.5\n-78.8\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n5\n6\nAmy\n1975\n6\n28\n6\n32.4\n-78.7\ntropical depression\nNaN\n25\n1012\nNaN\nNaN\n\n\n6\n7\nAmy\n1975\n6\n28\n12\n33.3\n-78.0\ntropical depression\nNaN\n25\n1011\nNaN\nNaN\n\n\n7\n8\nAmy\n1975\n6\n28\n18\n34.0\n-77.0\ntropical depression\nNaN\n30\n1006\nNaN\nNaN\n\n\n8\n9\nAmy\n1975\n6\n29\n0\n34.4\n-75.8\ntropical storm\nNaN\n35\n1004\nNaN\nNaN\n\n\n9\n10\nAmy\n1975\n6\n29\n6\n34.0\n-74.8\ntropical storm\nNaN\n40\n1002\nNaN\nNaN\n\n\n\n\n\n\n\n\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\n\n\nfrom pandas_datareader import wb\ndf = wb.download(\n    indicator=\"EN.ATM.CO2E.PC\",\n    country=[\"US\", \"CHN\", \"IND\", \"Z4\", \"Z7\"],\n    start=2017,\n    end=2017,\n)\n# remove country as index for ease of plotting with seaborn\ndf = df.reset_index()\n# wrap long country names\ndf[\"country\"] = df[\"country\"].apply(lambda x: textwrap.fill(x, 10))\n# order based on size\ndf = df.sort_values(\"EN.ATM.CO2E.PC\")\ndf.head()\n\n\nimport seaborn as sns\n\nfig, ax = plt.subplots()\nsns.barplot(x=\"country\", y=\"EN.ATM.CO2E.PC\", data=df.reset_index(), ax=ax)\nax.set_title(r\"CO$_2$ (metric tons per capita)\", loc=\"right\")\nplt.suptitle(\"The USA leads the world on per-capita emissions\", y=1.01)\nfor key, spine in ax.spines.items():\n    spine.set_visible(False)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\")\nax.yaxis.tick_right()\nplt.show()\n\n\nimport pandasdmx as pdmx\n# Tell pdmx we want OECD data\noecd = pdmx.Request(\"OECD\")\n# Set out everything about the request in the format specified by the OECD API\ndata = oecd.data(\n    resource_id=\"PDB_LV\",\n    key=\"GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010\",\n).to_pandas()\n\ndf = pd.DataFrame(data).reset_index()\ndf.head()\n\n\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\n\n\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n\n\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\n\n\nall_paras[1].text\n\n\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\n\n\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\n\n\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\n\n\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\n\n\nimport camelot\n# Grab the pdf\ntables = camelot.read_pdf(os.path.join('data', 'pdf_with_table.pdf'))\n\n\nimport textract\ntext = textract.process(Path('path/to/file.extension'))"
  },
  {
    "objectID": "practice/practice1.html",
    "href": "practice/practice1.html",
    "title": "演练1.1",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\n\n\n\n\n\n\n\n\nYear\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\n\n\n0\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n2\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n3\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n4\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 145 entries, 0 to 144\nData columns (total 19 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Year    145 non-null    int64  \n 1   Jan     145 non-null    float64\n 2   Feb     145 non-null    float64\n 3   Mar     145 non-null    float64\n 4   Apr     145 non-null    float64\n 5   May     145 non-null    float64\n 6   Jun     145 non-null    float64\n 7   Jul     145 non-null    float64\n 8   Aug     145 non-null    float64\n 9   Sep     145 non-null    float64\n 10  Oct     145 non-null    float64\n 11  Nov     145 non-null    float64\n 12  Dec     144 non-null    float64\n 13  J-D     144 non-null    float64\n 14  D-N     144 non-null    float64\n 15  DJF     144 non-null    float64\n 16  MAM     145 non-null    float64\n 17  JJA     145 non-null    float64\n 18  SON     145 non-null    float64\ndtypes: float64(18), int64(1)\nmemory usage: 21.6 KB\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。"
  },
  {
    "objectID": "practice/practice1.html#演练1.2",
    "href": "practice/practice1.html#演练1.2",
    "title": "演练1.1",
    "section": "演练1.2",
    "text": "演练1.2\n绘制温度和时间折线图\n\ndf = df.set_index(\"Year\")\ndf.head()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1880\n-0.39\n-0.53\n-0.23\n-0.30\n-0.05\n-0.18\n-0.22\n-0.25\n-0.24\n-0.30\n-0.43\n-0.42\n-0.30\nNaN\nNaN\n-0.20\n-0.22\n-0.32\n\n\n1881\n-0.31\n-0.25\n-0.06\n-0.02\n0.05\n-0.34\n0.09\n-0.06\n-0.28\n-0.44\n-0.37\n-0.24\n-0.19\n-0.20\n-0.33\n-0.01\n-0.10\n-0.37\n\n\n1882\n0.25\n0.21\n0.02\n-0.30\n-0.23\n-0.29\n-0.28\n-0.15\n-0.25\n-0.52\n-0.33\n-0.68\n-0.21\n-0.17\n0.08\n-0.17\n-0.24\n-0.37\n\n\n1883\n-0.57\n-0.66\n-0.15\n-0.30\n-0.26\n-0.12\n-0.06\n-0.23\n-0.34\n-0.17\n-0.44\n-0.15\n-0.29\n-0.33\n-0.64\n-0.23\n-0.14\n-0.32\n\n\n1884\n-0.16\n-0.11\n-0.64\n-0.59\n-0.36\n-0.41\n-0.41\n-0.52\n-0.45\n-0.44\n-0.58\n-0.47\n-0.43\n-0.40\n-0.14\n-0.53\n-0.45\n-0.49\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\nJan\nFeb\nMar\nApr\nMay\nJun\nJul\nAug\nSep\nOct\nNov\nDec\nJ-D\nD-N\nDJF\nMAM\nJJA\nSON\n\n\nYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2020\n1.59\n1.69\n1.66\n1.39\n1.27\n1.14\n1.10\n1.12\n1.19\n1.21\n1.58\n1.18\n1.34\n1.36\n1.56\n1.44\n1.12\n1.33\n\n\n2021\n1.25\n0.96\n1.20\n1.13\n1.05\n1.21\n1.07\n1.02\n1.05\n1.29\n1.29\n1.17\n1.14\n1.14\n1.13\n1.13\n1.10\n1.21\n\n\n2022\n1.24\n1.16\n1.41\n1.09\n1.02\n1.13\n1.06\n1.17\n1.15\n1.31\n1.09\n1.06\n1.16\n1.17\n1.19\n1.17\n1.12\n1.19\n\n\n2023\n1.29\n1.29\n1.64\n1.01\n1.13\n1.19\n1.44\n1.57\n1.67\n1.88\n1.97\n1.85\n1.50\n1.43\n1.22\n1.26\n1.40\n1.84\n\n\n2024\n1.67\n1.93\n1.77\n1.79\n1.44\n1.54\n1.42\n1.42\n1.58\n1.72\n1.90\nNaN\nNaN\n1.67\n1.82\n1.67\n1.46\n1.73\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ndf[\"Feb\"].plot(ax=ax)\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\n\n\n\n\n\n\n\n\n\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。"
  },
  {
    "objectID": "practice/practice1.html#演练1.3",
    "href": "practice/practice1.html#演练1.3",
    "title": "演练1.1",
    "section": "演练1.3",
    "text": "演练1.3\n制作年气温异常的折线图\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\n\n\n\n\n\n从上图的气温可以看出气温随着年份的增长而增长，尤其是近年来呈指数型增长，因此政府需要关注气候变化。"
  },
  {
    "objectID": "practice/practice1.html#演练1.4",
    "href": "practice/practice1.html#演练1.4",
    "title": "演练1.1",
    "section": "演练1.4",
    "text": "演练1.4\n创建直方图和频率表\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n\n\ndf[\"Period\"].tail(20)\n\nYear\n2005    1981—2010\n2006    1981—2010\n2007    1981—2010\n2008    1981—2010\n2009    1981—2010\n2010    1981—2010\n2011          NaN\n2012          NaN\n2013          NaN\n2014          NaN\n2015          NaN\n2016          NaN\n2017          NaN\n2018          NaN\n2019          NaN\n2020          NaN\n2021          NaN\n2022          NaN\n2023          NaN\n2024          NaN\nName: Period, dtype: category\nCategories (3, object): ['1921—1950' &lt; '1951—1980' &lt; '1981—2010']\n\n\n\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\n\nYear     \n1880  Jun   -0.18\n      Jul   -0.22\n      Aug   -0.25\n1881  Jun   -0.34\n      Jul    0.09\ndtype: float64\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();"
  },
  {
    "objectID": "practice/practice1.html#演练1.5",
    "href": "practice/practice1.html#演练1.5",
    "title": "演练1.1",
    "section": "演练1.5",
    "text": "演练1.5\n\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1951\nJan\n-0.36\n\n\n1\n1951\nFeb\n-0.51\n\n\n2\n1951\nMar\n-0.18\n\n\n3\n1951\nApr\n0.06\n\n\n4\n1951\nMay\n0.17\n\n\n...\n...\n...\n...\n\n\n355\n1980\nAug\n0.10\n\n\n356\n1980\nSep\n0.10\n\n\n357\n1980\nOct\n0.12\n\n\n358\n1980\nNov\n0.21\n\n\n359\n1980\nDec\n0.09\n\n\n\n\n360 rows × 3 columns\n\n\n\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\nThe cold threshold of 30.0% is -0.1\nThe hot threshold of 70.0% is 0.1\n\n\n根据上述的表格信息和结果输出，我们在这段时间内更频繁地经历更热的天气。"
  },
  {
    "objectID": "practice/practice1.html#演练1.6",
    "href": "practice/practice1.html#演练1.6",
    "title": "演练1.1",
    "section": "演练1.6",
    "text": "演练1.6\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\n\n\n\n\n\n\n\n\nYear\nmonth\nvalues\n\n\n\n\n0\n1981\nJan\n0.80\n\n\n1\n1981\nFeb\n0.62\n\n\n2\n1981\nMar\n0.68\n\n\n3\n1981\nApr\n0.39\n\n\n4\n1981\nMay\n0.18\n\n\n\n\n\n\n\n\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\n\nThe proportion under -0.1 is 1.94%\n\n\n\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\nThe proportion over 0.1 is 84.72%"
  },
  {
    "objectID": "practice/practice1.html#演练1.7",
    "href": "practice/practice1.html#演练1.7",
    "title": "演练1.1",
    "section": "演练1.7",
    "text": "演练1.7\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\n\n\n\n\n\n\n\n\nYear\nSeason\nValues\nPeriod\n\n\n\n\n444\n1991\nMAM\n0.45\n1981—2010\n\n\n445\n1991\nJJA\n0.42\n1981—2010\n\n\n446\n1991\nSON\n0.32\n1981—2010\n\n\n447\n1992\nDJF\n0.43\n1981—2010\n\n\n448\n1992\nMAM\n0.29\n1981—2010\n\n\n449\n1992\nJJA\n-0.04\n1981—2010\n\n\n450\n1992\nSON\n-0.15\n1981—2010\n\n\n451\n1993\nDJF\n0.37\n1981—2010\n\n\n452\n1993\nMAM\n0.31\n1981—2010\n\n\n453\n1993\nJJA\n0.12\n1981—2010\n\n\n\n\n\n\n\n\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\n\n\n\n\n\n\n\n\n\nmean\nvar\n\n\nSeason\nPeriod\n\n\n\n\n\n\nDJF\n1921—1950\n-0.025862\n0.057489\n\n\n1951—1980\n-0.002000\n0.050548\n\n\n1981—2010\n0.523333\n0.078975\n\n\nJJA\n1921—1950\n-0.053448\n0.021423\n\n\n1951—1980\n0.000000\n0.014697\n\n\n1981—2010\n0.400000\n0.067524\n\n\nMAM\n1921—1950\n-0.041034\n0.031302\n\n\n1951—1980\n0.000333\n0.025245\n\n\n1981—2010\n0.509333\n0.075737\n\n\nSON\n1921—1950\n0.083448\n0.027473\n\n\n1951—1980\n-0.001333\n0.026205\n\n\n1981—2010\n0.429000\n0.111127\n\n\n\n\n\n\n\n\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n              1951—1980 average\n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1880\n            \n          \n        \n        \n          \n          \n          \n            \n              1900\n            \n          \n        \n        \n          \n          \n          \n            \n              1920\n            \n          \n        \n        \n          \n          \n          \n            \n              1940\n            \n          \n        \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2020\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -1.0\n            \n          \n        \n        \n          \n            \n              -0.5\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.5\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n        \n          \n            \n              1.5\n            \n          \n        \n      \n    \n    \n      \n        Average annual temperature anomaly in\n      \n      \n        in the northern hemisphere (1880—2024)\n      \n    \n    \n      \n        Annual temperature anomalies\n      \n    \n    \n      \n        Year\n      \n    \n    \n      \n      \n      \n        \n          \n            Season\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                MAM\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                JJA\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                SON\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n              \n              \n              \n            \n            \n              \n                DJF"
  },
  {
    "objectID": "practice/practice1.html#演练1.8",
    "href": "practice/practice1.html#演练1.8",
    "title": "演练1.1",
    "section": "演练1.8",
    "text": "演练1.8\n\ndf_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n0\n1958\n3\n315.71\n315.71\n314.62\n\n\n1\n1958\n4\n317.45\n317.45\n315.29\n\n\n2\n1958\n5\n317.50\n317.50\n314.71\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n4\n1958\n7\n315.86\n315.86\n314.98\n\n\n\n\n\n\n\n\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\n\n\n\n\n\n\n\n\nYear\nMonth\nMonthly average\nInterpolated\nTrend\n\n\n\n\n3\n1958\n6\n-99.99\n317.10\n314.85\n\n\n15\n1959\n6\n318.15\n318.15\n315.92\n\n\n27\n1960\n6\n319.59\n319.59\n317.36\n\n\n39\n1961\n6\n319.77\n319.77\n317.48\n\n\n51\n1962\n6\n320.55\n320.55\n318.27\n\n\n\n\n\n\n\n\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n\n\n\n\n\n\n\n\nYear\nJun\nTrend\n\n\n\n\n0\n1958\n0.05\n314.85\n\n\n1\n1959\n0.14\n315.92\n\n\n2\n1960\n0.18\n317.36\n\n\n3\n1961\n0.18\n317.48\n\n\n4\n1962\n-0.13\n318.27\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.0\n            \n          \n        \n        \n          \n          \n          \n            \n              0.2\n            \n          \n        \n        \n          \n          \n          \n            \n              0.4\n            \n          \n        \n        \n          \n          \n          \n            \n              0.6\n            \n          \n        \n        \n          \n          \n          \n            \n              0.8\n            \n          \n        \n        \n          \n          \n          \n            \n              1.0\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              320\n            \n          \n        \n        \n          \n            \n              340\n            \n          \n        \n        \n          \n            \n              360\n            \n          \n        \n        \n          \n            \n              380\n            \n          \n        \n        \n          \n            \n              400\n            \n          \n        \n      \n    \n    \n      \n        Scatterplot of temperature anomalies vs carbon dioxide emissions\n      \n    \n    \n      \n        Carbon dioxide levels (trend, mole fraction)\n      \n    \n    \n      \n        Temperature anomaly (degrees Celsius)\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n\n\n\n\n\n\n\n\nJun\nTrend\n\n\n\n\nJun\n1.000000\n0.915419\n\n\nTrend\n0.915419\n1.000000\n\n\n\n\n\n\n\n\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\n\n\n  \n  \n    \n    \n    \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n          \n          \n            \n              1960\n            \n          \n        \n        \n          \n          \n          \n            \n              1970\n            \n          \n        \n        \n          \n          \n          \n            \n              1980\n            \n          \n        \n        \n          \n          \n          \n            \n              1990\n            \n          \n        \n        \n          \n          \n          \n            \n              2000\n            \n          \n        \n        \n          \n          \n          \n            \n              2010\n            \n          \n        \n        \n        \n      \n      \n        \n          \n            \n              -0.2\n            \n          \n        \n        \n          \n            \n              0.0\n            \n          \n        \n        \n          \n            \n              0.2\n            \n          \n        \n        \n          \n            \n              0.4\n            \n          \n        \n        \n          \n            \n              0.6\n            \n          \n        \n        \n          \n            \n              0.8\n            \n          \n        \n        \n          \n            \n              1.0\n            \n          \n        \n      \n    \n    \n      \n        June temperature anomalies\n      \n    \n    \n      \n        Jun\n      \n    \n    \n      \n        Year\n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n\n\n  \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                -0.2\n              \n            \n          \n          \n            \n              \n                0.0\n              \n            \n          \n          \n            \n              \n                0.2\n              \n            \n          \n          \n            \n              \n                0.4\n              \n            \n          \n          \n            \n              \n                0.6\n              \n            \n          \n          \n            \n              \n                0.8\n              \n            \n          \n          \n            \n              \n                1.0\n              \n            \n          \n        \n      \n      \n        \n          June temperature anomalies\n        \n      \n      \n        \n          Jun\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n  \n    \n    \n      \n      \n      \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n          \n          \n          \n          \n          \n          \n          \n          \n          \n        \n        \n          \n            \n              \n              \n            \n          \n          \n            \n            \n          \n        \n        \n          \n            \n            \n            \n              \n                1960\n              \n            \n          \n          \n            \n            \n            \n              \n                1970\n              \n            \n          \n          \n            \n            \n            \n              \n                1980\n              \n            \n          \n          \n            \n            \n            \n              \n                1990\n              \n            \n          \n          \n            \n            \n            \n              \n                2000\n              \n            \n          \n          \n            \n            \n            \n              \n                2010\n              \n            \n          \n          \n          \n        \n        \n          \n            \n              \n                320\n              \n            \n          \n          \n            \n              \n                340\n              \n            \n          \n          \n            \n              \n                360\n              \n            \n          \n          \n            \n              \n                380\n              \n            \n          \n          \n            \n              \n                400\n              \n            \n          \n        \n      \n      \n        \n          Carbon dioxide emissions\n        \n      \n      \n        \n          Trend\n        \n      \n      \n        \n          Year\n        \n      \n      \n      \n    \n    \n    \n  \n\n\n\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zhang Yi’s website and data analysis portfolio",
    "section": "",
    "text": "Hello, and thanks for visiting!\nWelcome to my website and data analysis portfolio.\nHere, I’ll feature my projects for the Fall 2024 Informational technologies in Business class.\nPlease use the Menu Bar above to look around."
  },
  {
    "objectID": "homework/zhangyi homework4-Lecture 4(1).html",
    "href": "homework/zhangyi homework4-Lecture 4(1).html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv('all-ages.csv')\n\n\ndf\n\n\n\n\n\n\n\n\nMajor_code\nMajor\nMajor_category\nTotal\nEmployed\nEmployed_full_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\n\n\n\n\n0\n1100\nGENERAL AGRICULTURE\nAgriculture & Natural Resources\n128148\n90245\n74078\n2423\n0.026147\n50000\n34000\n80000.0\n\n\n1\n1101\nAGRICULTURE PRODUCTION AND MANAGEMENT\nAgriculture & Natural Resources\n95326\n76865\n64240\n2266\n0.028636\n54000\n36000\n80000.0\n\n\n2\n1102\nAGRICULTURAL ECONOMICS\nAgriculture & Natural Resources\n33955\n26321\n22810\n821\n0.030248\n63000\n40000\n98000.0\n\n\n3\n1103\nANIMAL SCIENCES\nAgriculture & Natural Resources\n103549\n81177\n64937\n3619\n0.042679\n46000\n30000\n72000.0\n\n\n4\n1104\nFOOD SCIENCE\nAgriculture & Natural Resources\n24280\n17281\n12722\n894\n0.049188\n62000\n38500\n90000.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n6211\nHOSPITALITY MANAGEMENT\nBusiness\n200854\n163393\n122499\n8862\n0.051447\n49000\n33000\n70000.0\n\n\n169\n6212\nMANAGEMENT INFORMATION SYSTEMS AND STATISTICS\nBusiness\n156673\n134478\n118249\n6186\n0.043977\n72000\n50000\n100000.0\n\n\n170\n6299\nMISCELLANEOUS BUSINESS & MEDICAL ADMINISTRATION\nBusiness\n102753\n77471\n61603\n4308\n0.052679\n53000\n36000\n83000.0\n\n\n171\n6402\nHISTORY\nHumanities & Liberal Arts\n712509\n478416\n354163\n33725\n0.065851\n50000\n35000\n80000.0\n\n\n172\n6403\nUNITED STATES HISTORY\nHumanities & Liberal Arts\n17746\n11887\n8204\n943\n0.073500\n50000\n39000\n81000.0\n\n\n\n\n173 rows × 11 columns\n\n\n\n\n# 按照专业分组，并把失业率从低到高升序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"Unemployment_rate\"])\nprint(result)\n\n                                            Major_code  \\\nMajor                                                    \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING            2411   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION        2301   \nPHARMACOLOGY                                      3607   \nMATERIALS SCIENCE                                 5008   \nMATHEMATICS AND COMPUTER SCIENCE                  4005   \n...                                                ...   \nLIBRARY SCIENCE                                   3501   \nSCHOOL STUDENT COUNSELING                         2303   \nMILITARY TECHNOLOGIES                             3801   \nCLINICAL PSYCHOLOGY                               5202   \nMISCELLANEOUS FINE ARTS                           6099   \n\n                                                                 Major_category  \\\nMajor                                                                             \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                              Engineering   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                            Education   \nPHARMACOLOGY                                             Biology & Life Science   \nMATERIALS SCIENCE                                                   Engineering   \nMATHEMATICS AND COMPUTER SCIENCE                        Computers & Mathematics   \n...                                                                         ...   \nLIBRARY SCIENCE                                                       Education   \nSCHOOL STUDENT COUNSELING                                             Education   \nMILITARY TECHNOLOGIES                       Industrial Arts & Consumer Services   \nCLINICAL PSYCHOLOGY                                    Psychology & Social Work   \nMISCELLANEOUS FINE ARTS                                                    Arts   \n\n                                            Total  Employed  \\\nMajor                                                         \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       6264      4120   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   4037      3113   \nPHARMACOLOGY                                 5015      3481   \nMATERIALS SCIENCE                            7208      5866   \nMATHEMATICS AND COMPUTER SCIENCE             7184      5874   \n...                                           ...       ...   \nLIBRARY SCIENCE                             16193      7091   \nSCHOOL STUDENT COUNSELING                    2396      1492   \nMILITARY TECHNOLOGIES                        4315      1650   \nCLINICAL PSYCHOLOGY                          7638      5128   \nMISCELLANEOUS FINE ARTS                      8511      6431   \n\n                                            Employed_full_time_year_round  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING                               3350   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION                           2468   \nPHARMACOLOGY                                                         2579   \nMATERIALS SCIENCE                                                    4505   \nMATHEMATICS AND COMPUTER SCIENCE                                     5039   \n...                                                                   ...   \nLIBRARY SCIENCE                                                      4330   \nSCHOOL STUDENT COUNSELING                                            1093   \nMILITARY TECHNOLOGIES                                                1708   \nCLINICAL PSYCHOLOGY                                                  3297   \nMISCELLANEOUS FINE ARTS                                              3802   \n\n                                            Unemployed  Unemployment_rate  \\\nMajor                                                                       \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING               0           0.000000   \nEDUCATIONAL ADMINISTRATION AND SUPERVISION           0           0.000000   \nPHARMACOLOGY                                        57           0.016111   \nMATERIALS SCIENCE                                  134           0.022333   \nMATHEMATICS AND COMPUTER SCIENCE                   150           0.024900   \n...                                                ...                ...   \nLIBRARY SCIENCE                                    743           0.094843   \nSCHOOL STUDENT COUNSELING                          169           0.101746   \nMILITARY TECHNOLOGIES                              187           0.101796   \nCLINICAL PSYCHOLOGY                                587           0.102712   \nMISCELLANEOUS FINE ARTS                           1190           0.156147   \n\n                                            Median  P25th     P75th  \nMajor                                                                \nGEOLOGICAL AND GEOPHYSICAL ENGINEERING       85000  55000  125000.0  \nEDUCATIONAL ADMINISTRATION AND SUPERVISION   58000  44750   79000.0  \nPHARMACOLOGY                                 60000  35000  105000.0  \nMATERIALS SCIENCE                            75000  60000  100000.0  \nMATHEMATICS AND COMPUTER SCIENCE             92000  53000  136000.0  \n...                                            ...    ...       ...  \nLIBRARY SCIENCE                              40000  30000   55000.0  \nSCHOOL STUDENT COUNSELING                    41000  33200   50000.0  \nMILITARY TECHNOLOGIES                        64000  39750   90000.0  \nCLINICAL PSYCHOLOGY                          45000  26100   62000.0  \nMISCELLANEOUS FINE ARTS                      45000  30000   60000.0  \n\n[173 rows x 10 columns]\n\n\n\nimport pandas as pd\ndf = pd.read_csv('recent-grads.csv')\ndf\n\n\n\n\n\n\n\n\nRank\nMajor_code\nMajor\nTotal\nMen\nWomen\nMajor_category\nShareWomen\nSample_size\nEmployed\n...\nPart_time\nFull_time_year_round\nUnemployed\nUnemployment_rate\nMedian\nP25th\nP75th\nCollege_jobs\nNon_college_jobs\nLow_wage_jobs\n\n\n\n\n0\n1\n2419\nPETROLEUM ENGINEERING\n2339.0\n2057.0\n282.0\nEngineering\n0.120564\n36\n1976\n...\n270\n1207\n37\n0.018381\n110000\n95000\n125000\n1534\n364\n193\n\n\n1\n2\n2416\nMINING AND MINERAL ENGINEERING\n756.0\n679.0\n77.0\nEngineering\n0.101852\n7\n640\n...\n170\n388\n85\n0.117241\n75000\n55000\n90000\n350\n257\n50\n\n\n2\n3\n2415\nMETALLURGICAL ENGINEERING\n856.0\n725.0\n131.0\nEngineering\n0.153037\n3\n648\n...\n133\n340\n16\n0.024096\n73000\n50000\n105000\n456\n176\n0\n\n\n3\n4\n2417\nNAVAL ARCHITECTURE AND MARINE ENGINEERING\n1258.0\n1123.0\n135.0\nEngineering\n0.107313\n16\n758\n...\n150\n692\n40\n0.050125\n70000\n43000\n80000\n529\n102\n0\n\n\n4\n5\n2405\nCHEMICAL ENGINEERING\n32260.0\n21239.0\n11021.0\nEngineering\n0.341631\n289\n25694\n...\n5180\n16697\n1672\n0.061098\n65000\n50000\n75000\n18314\n4440\n972\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n168\n169\n3609\nZOOLOGY\n8409.0\n3050.0\n5359.0\nBiology & Life Science\n0.637293\n47\n6259\n...\n2190\n3602\n304\n0.046320\n26000\n20000\n39000\n2771\n2947\n743\n\n\n169\n170\n5201\nEDUCATIONAL PSYCHOLOGY\n2854.0\n522.0\n2332.0\nPsychology & Social Work\n0.817099\n7\n2125\n...\n572\n1211\n148\n0.065112\n25000\n24000\n34000\n1488\n615\n82\n\n\n170\n171\n5202\nCLINICAL PSYCHOLOGY\n2838.0\n568.0\n2270.0\nPsychology & Social Work\n0.799859\n13\n2101\n...\n648\n1293\n368\n0.149048\n25000\n25000\n40000\n986\n870\n622\n\n\n171\n172\n5203\nCOUNSELING PSYCHOLOGY\n4626.0\n931.0\n3695.0\nPsychology & Social Work\n0.798746\n21\n3777\n...\n965\n2738\n214\n0.053621\n23400\n19200\n26000\n2403\n1245\n308\n\n\n172\n173\n3501\nLIBRARY SCIENCE\n1098.0\n134.0\n964.0\nEducation\n0.877960\n2\n742\n...\n237\n410\n87\n0.104946\n22000\n20000\n22000\n288\n338\n192\n\n\n\n\n173 rows × 21 columns\n\n\n\n\n# 按照专业分组，将女生占比从高到低降序排列\nresult = df.groupby([\"Major\"]).sum().sort_values([\"ShareWomen\"],ascending=False)\nprint(result)\n\n                                               Rank  Major_code     Total  \\\nMajor                                                                       \nEARLY CHILDHOOD EDUCATION                       165        2307   37589.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   164        6102   38279.0   \nMEDICAL ASSISTING SERVICES                       52        6104   11123.0   \nELEMENTARY EDUCATION                            139        2304  170862.0   \nFAMILY AND CONSUMER SCIENCES                    151        2901   58001.0   \n...                                             ...         ...       ...   \nMINING AND MINERAL ENGINEERING                    2        2416     756.0   \nCONSTRUCTION SERVICES                            27        5601   18498.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      67        2504    4790.0   \nMILITARY TECHNOLOGIES                            74        3801     124.0   \nFOOD SCIENCE                                     22        1104       0.0   \n\n                                                   Men     Women  \\\nMajor                                                              \nEARLY CHILDHOOD EDUCATION                       1167.0   36422.0   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   1225.0   37054.0   \nMEDICAL ASSISTING SERVICES                       803.0   10320.0   \nELEMENTARY EDUCATION                           13029.0  157833.0   \nFAMILY AND CONSUMER SCIENCES                    5166.0   52835.0   \n...                                                ...       ...   \nMINING AND MINERAL ENGINEERING                   679.0      77.0   \nCONSTRUCTION SERVICES                          16820.0    1678.0   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     4419.0     371.0   \nMILITARY TECHNOLOGIES                            124.0       0.0   \nFOOD SCIENCE                                       0.0       0.0   \n\n                                                                    Major_category  \\\nMajor                                                                                \nEARLY CHILDHOOD EDUCATION                                                Education   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                               Health   \nMEDICAL ASSISTING SERVICES                                                  Health   \nELEMENTARY EDUCATION                                                     Education   \nFAMILY AND CONSUMER SCIENCES                   Industrial Arts & Consumer Services   \n...                                                                            ...   \nMINING AND MINERAL ENGINEERING                                         Engineering   \nCONSTRUCTION SERVICES                          Industrial Arts & Consumer Services   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                            Engineering   \nMILITARY TECHNOLOGIES                          Industrial Arts & Consumer Services   \nFOOD SCIENCE                                       Agriculture & Natural Resources   \n\n                                               ShareWomen  Sample_size  \\\nMajor                                                                    \nEARLY CHILDHOOD EDUCATION                        0.968954          342   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES    0.967998           95   \nMEDICAL ASSISTING SERVICES                       0.927807           67   \nELEMENTARY EDUCATION                             0.923745         1629   \nFAMILY AND CONSUMER SCIENCES                     0.910933          518   \n...                                                   ...          ...   \nMINING AND MINERAL ENGINEERING                   0.101852            7   \nCONSTRUCTION SERVICES                            0.090713          295   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES      0.077453           71   \nMILITARY TECHNOLOGIES                            0.000000            4   \nFOOD SCIENCE                                     0.000000           36   \n\n                                               Employed  Full_time  Part_time  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                         32551      27569       7001   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES     29763      19975      13862   \nMEDICAL ASSISTING SERVICES                         9168       5643       4107   \nELEMENTARY EDUCATION                             149339     123177      37965   \nFAMILY AND CONSUMER SCIENCES                      46624      36747      15872   \n...                                                 ...        ...        ...   \nMINING AND MINERAL ENGINEERING                      640        556        170   \nCONSTRUCTION SERVICES                             16318      15690       1751   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES        4186       4175        247   \nMILITARY TECHNOLOGIES                                 0        111          0   \nFOOD SCIENCE                                       3149       2558       1121   \n\n                                               Full_time_year_round  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                                     20748   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES                 14460   \nMEDICAL ASSISTING SERVICES                                     4290   \nELEMENTARY EDUCATION                                          86540   \nFAMILY AND CONSUMER SCIENCES                                  26906   \n...                                                             ...   \nMINING AND MINERAL ENGINEERING                                  388   \nCONSTRUCTION SERVICES                                         12313   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES                    3607   \nMILITARY TECHNOLOGIES                                           111   \nFOOD SCIENCE                                                   1735   \n\n                                               Unemployed  Unemployment_rate  \\\nMajor                                                                          \nEARLY CHILDHOOD EDUCATION                            1360           0.040105   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES        1487           0.047584   \nMEDICAL ASSISTING SERVICES                            407           0.042507   \nELEMENTARY EDUCATION                                 7297           0.046586   \nFAMILY AND CONSUMER SCIENCES                         3355           0.067128   \n...                                                   ...                ...   \nMINING AND MINERAL ENGINEERING                         85           0.117241   \nCONSTRUCTION SERVICES                                1042           0.060023   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES           250           0.056357   \nMILITARY TECHNOLOGIES                                   0           0.000000   \nFOOD SCIENCE                                          338           0.096931   \n\n                                               Median  P25th  P75th  \\\nMajor                                                                 \nEARLY CHILDHOOD EDUCATION                       28000  21000  35000   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES   28000  20000  40000   \nMEDICAL ASSISTING SERVICES                      42000  30000  65000   \nELEMENTARY EDUCATION                            32000  23400  38000   \nFAMILY AND CONSUMER SCIENCES                    30000  22900  40000   \n...                                               ...    ...    ...   \nMINING AND MINERAL ENGINEERING                  75000  55000  90000   \nCONSTRUCTION SERVICES                           50000  36000  60000   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES     40000  27000  52000   \nMILITARY TECHNOLOGIES                           40000  40000  40000   \nFOOD SCIENCE                                    53000  32000  70000   \n\n                                               College_jobs  Non_college_jobs  \\\nMajor                                                                           \nEARLY CHILDHOOD EDUCATION                             23515              7705   \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES         19957              9404   \nMEDICAL ASSISTING SERVICES                             2091              6948   \nELEMENTARY EDUCATION                                 108085             36972   \nFAMILY AND CONSUMER SCIENCES                          20985             20133   \n...                                                     ...               ...   \nMINING AND MINERAL ENGINEERING                          350               257   \nCONSTRUCTION SERVICES                                  3275              5351   \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES            1861              2121   \nMILITARY TECHNOLOGIES                                     0                 0   \nFOOD SCIENCE                                           1183              1274   \n\n                                               Low_wage_jobs  \nMajor                                                         \nEARLY CHILDHOOD EDUCATION                               2868  \nCOMMUNICATION DISORDERS SCIENCES AND SERVICES           5125  \nMEDICAL ASSISTING SERVICES                              1270  \nELEMENTARY EDUCATION                                   11502  \nFAMILY AND CONSUMER SCIENCES                            5248  \n...                                                      ...  \nMINING AND MINERAL ENGINEERING                            50  \nCONSTRUCTION SERVICES                                    703  \nMECHANICAL ENGINEERING RELATED TECHNOLOGIES              406  \nMILITARY TECHNOLOGIES                                      0  \nFOOD SCIENCE                                             485  \n\n[173 rows x 20 columns]\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\na=df['Median'].groupby(df['Major_category']).sum()\na.plot.bar()\nplt.show()"
  },
  {
    "objectID": "homework/Zhang yi-homework/Zhangyi(3).html",
    "href": "homework/Zhang yi-homework/Zhangyi(3).html",
    "title": "",
    "section": "",
    "text": "# %load Zhangyi(3).py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 读取 CSV 文件\ndf = pd.read_csv('plastic-waste.csv')\n\n# 清理数据：去除缺失值\ndf_cleaned = df.dropna(subset=['continent', 'plastic_waste_per_cap', 'mismanaged_plastic_waste_per_cap'])\n\n# 绘制散点图\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='plastic_waste_per_cap', y='mismanaged_plastic_waste_per_cap', hue='continent', data=df_cleaned, palette='deep')\n\n# 设置图表标题和坐标轴标签\nplt.title(\"Relationship between Plastic Waste Per Capita and Mismanaged Plastic Waste Per Capita\")\nplt.xlabel(\"Plastic Waste Per Capita (kg)\")\nplt.ylabel(\"Mismanaged Plastic Waste Per Capita (kg)\")\n\n# 显示图例\nplt.legend(title='Continent')\n\n# 显示图形\nplt.show()"
  },
  {
    "objectID": "homework/Zhang yi-homework/Zhangyi(1).html",
    "href": "homework/Zhang yi-homework/Zhangyi(1).html",
    "title": "",
    "section": "",
    "text": "# %load Zhangyi(1).py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 读取 CSV 文件\ndf = pd.read_csv('plastic-waste.csv')\n\n# 清理数据：去除缺失值\ndf_cleaned = df.dropna(subset=['continent', 'plastic_waste_per_cap'])\n\n# 设置图形风格\nsns.set(style=\"whitegrid\")\n\n# 创建 FacetGrid，按 'continent' 分面\ng = sns.FacetGrid(df_cleaned, col='continent', col_wrap=3, height=4, sharey=False)\ng.map(sns.histplot, 'plastic_waste_per_cap', kde=False, bins=20, color='blue')\n\n# 设置图表标题和坐标轴标签\ng.set_titles(\"{col_name}\")\ng.set_axis_labels(\"Plastic Waste Per Capita (kg)\", \"Frequency\")\ng.fig.suptitle(\"Distribution of Plastic Waste Per Capita by Continent\", fontsize=16)\ng.tight_layout(pad=2)\n\n# 显示图形\nplt.show()"
  },
  {
    "objectID": "homework/workflow-basics(1).html",
    "href": "homework/workflow-basics(1).html",
    "title": "",
    "section": "",
    "text": "(workflow-basics)= # Workflow Basics\nThis chapter will take you through some of the essential parts of a Python workflow."
  },
  {
    "objectID": "homework/workflow-basics(1).html#prerequisites",
    "href": "homework/workflow-basics(1).html#prerequisites",
    "title": "",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou’ll need an installation of Python and Visual Studio Code with the Python extensions to get to grips with this chapter. If you haven’t installed those yet, head back to {ref}code-preliminaries and follow the instructions there."
  },
  {
    "objectID": "homework/workflow-basics(1).html#working-with-python-scripts-and-the-interactive-window",
    "href": "homework/workflow-basics(1).html#working-with-python-scripts-and-the-interactive-window",
    "title": "",
    "section": "Working with Python scripts and the interactive window",
    "text": "Working with Python scripts and the interactive window\nAs a reminder, the figure below shows the typical layout of Visual Studio Code.\n\n\n\nA typical user view in Visual Studio Code\n\n\nWhen you create a new script (File-&gt;New File-&gt;Save as ’your_script_name.py), it will appear in the part of the screen labelled as 3.\nTo run a script, select the code you want to run, right click, and select “Run Selection/Line in Interactive Window”. You can also hit shift + enter if you set this shortcut up; if you haven’t it’s well worth doing and you can find the instructions in {ref}code-preliminaries.\nUsing the “Run Selection/Line in Interactive Window” option or using the shortcut will cause panel 5 in the above diagram (the interactive window) to appear, where you will see the code run and the outputs of your script appear.\nIf you have an issue getting the code to run in the interactive window, first check the instructions in {ref}`code-preliminaries`. If you're still having issues, it may be that Visual Studio Code isn't sure which Python to run, or where Python is on your system. To fix the latter problem, hit the \"Select kernel\" button in the top right-hand side of the interactive window.\nWhen you are first writing a script, it’s useful to be able to move back and forth between the script and the interactive window. You might execute a line of code (put the cursor on the relevant line and hit shift and enter) in the interactive window, then manually write out some code in the interactive window’s execution box (seen at the bottom of panel 5 saying “Type code here…”), and then explore some of the variables you’ve created with the variable explorer (using the button “Variables”) at the top of the interactive window.\nBut, once you’ve honed the code in your script, it’s good to make the script a complete analytical process that you are happy running end-to-end and that—for production or ‘final’ work—you would use the “Run Current File in Interactive Window” option to run all the way through. This is good practice because what is in your script is reproducible but what you’ve entered manually in the interactive window is not. And you want the outputs from your code to be reproducible and understandable by others (including future you!), but this is hard if there are undocumented extra lines of code that you only did on the fly via the interactive window’s execution box."
  },
  {
    "objectID": "homework/workflow-basics(1).html#using-installed-packages-and-modules",
    "href": "homework/workflow-basics(1).html#using-installed-packages-and-modules",
    "title": "",
    "section": "Using installed packages and modules",
    "text": "Using installed packages and modules\nWe already saw how to install packages in {ref}code-preliminaries. If you forgot, look back at how to do this now. In short, packages are installed using the command line or, on Windows, the Anaconda prompt. With either of these open, type conda install packagename and hit enter to both search for and install the package you need.\nWhat about using a package that you’ve installed? That’s what we’ll look at now.\nLet’s see an example of using the powerful numerical library numpy. There are different ways to import packages to use within a script or notebook; you can import the entire package in one go or just import the functions you need (if you know their names). When an entire package is imported, you can give it any name you like and the convention for numpy is to import it as the shortened ‘np’. All of the functions and methods of the package can be accessed by typing np followed by . and then typing the function name. This convention of importing packages with a given name makes your code easier to read, because you know exactly which package is doing what, and avoids any conflicts when functions from different packages have the same name.\nAs well as demonstrating importing the whole package for numpy, the example below shows importing just one specific function from numpy, inv, which does matrix inversion. Note that because inv was imported separately it can be used without an np prefix.\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\nWe could have imported all of numpy and it used it without extension using from numpy import * but this is considered bad practice as it fills our ‘namespace’ with function names that might clash with other packages and it’s less easy to read because you don’t know which function came from which package (one of Python’s mantras is “explicit is better than implict”). However, some packages are designed to be used like this, so, for example, you will see from lets_plot import * in this book.\nIf you want to check what packages you have installed in your Python environment, run `conda list` on your computer's command line (aka the *terminal* or *command prompt*).\nSometimes you might forget what a function you have imported does! Or at least, you might not be sure what all of the optional arguments are. In Visual Studio Code, you can just hover your cursor over the name of the function and a box will come up that tells you everything you need to know about it. This box is auto-generated by doc-strings; information that is written in text just under a function’s definition (def statement).\nAn alternative way to see what a function does is to use a wonderful package called rich that does many things including providing an inspect() function. You will need to use pip to install rich by running pip install rich on the command line. Here’s an example of using rich’s inpsect method on the inv() function we imported above (methods=True reports all of the functionality of inv()):\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\ngdnkbtsnihaa Exercise Write a code block that imports the **numpy** function `numpy.linalg.det()` as `det()`. Run `inspect()` on it. Find the determinant of `[[4, 3], [1, 7]]`.\n\nModules\nSometimes, you will want to call in some code from a different script that you wrote (rather than from a package provided by someone else). Imagine you have several scripts with code in, a, b, and c, all of which need to use the same underlying function that you have written. What do you do? (Note that “script with code in” is just a text file that has a .py extension and contains code.)\nA central tenet of good coding is that you do not repeat yourself. Therefore, a bad solution to this problem would be to copy and paste the same code into all three of the scripts. A good solution is to write the code that’s need just once in a separate ‘utility’ script and have the other scripts import that one function. This also adheres to another important programming principle: that of writing modular code.\nThis schematic shows the kind of situation we’re talking about:\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\nHow can we give code files a, b, and c access to the functions etc in the “Utility script”? We would define a file ‘utilities.py’ that had the following function in that we would like to use in the other code files:\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\nThen, in ‘code_script_a.py’, we would write:\n\nimport utilities as utils\n\nprint(utils.really_useful_func(20))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 import utilities as utils\n      3 print(utils.really_useful_func(20))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAn alternative is to just import the function we want, with the name we want:\n\nfrom utilities import really_useful_func as ru_fn\n\nprint(ru_fn(30))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 from utilities import really_useful_func as ru_fn\n      3 print(ru_fn(30))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAnother important example is the case where you want to run ‘utilities.py’ as a standalone script, but still want to borrow functions from it to run in other scripts. There’s a way to do this. Let’s change utilities.py to\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\n\n\ndef default_func():\n    print('Script has run')\n\n\nif __name__ == '__main__':\n    default_func()\nWhat this says is that if we call ‘utilities.py’ from the command line, eg\npython utilities.py\nIt will return Script has run because, by executing the script alone, we are asking for anything in the main block defined at the end of the file to be run. But we can still import anything from utilities into other scripts as before–and in that case it is not the main script, but an import, and so the main block will not be executed by default.\nYou can important several functions at once from a module (aka another script file) like this:\nfrom utilities import really_useful_func, default_func\ngdnkbtsnihaa Exercise Write your own `utilities.py` that has a `super_useful_func` that accepts a number and returns the number divided by 10. In another script, `main.py`, try a) importing all of utilities and running `super_useful_func` on a number and, b), importing just `super_useful_func` from utilities and running it on a number."
  },
  {
    "objectID": "homework/workflow-basics(1).html#reading-and-writing-files",
    "href": "homework/workflow-basics(1).html#reading-and-writing-files",
    "title": "",
    "section": "Reading and writing files",
    "text": "Reading and writing files\nAlthough most applications in economics will use the pandas package to read and write tabular data, it’s sometimes useful to know how to read and write arbitrary files using the built-in Python libraries too. To open a file\nopen('filename', mode)\nwhere mode could be r for read, a for append, w for write, and x to create a file. Create a file called text_example.txt and write a single line in it, ‘hello world’. To open the file and print the text, use:\nwith open('text_example.txt') as f:\n    text_in = f.read()\n\nprint(text_in)\n'hello world!\\n'\n\\n is the new line character. Now let’s try adding a line to the file:\nwith open('text_example.txt', 'a') as f:\n    f.write('this is another line\\n')\nWriting and reading files using the with command is a quick and convenient shorthand for the less concise open, action, close pattern. For example, the above example can also be written as:\nf = open('text_example.txt', 'a')\nf.write('this is another line\\n')\nf.close()\nAlthough this short example shows opening and writing a text file, this approach can be used to edit a wide range of file extensions including .json, .xml, .csv, .tsv, and many more, including binary files in addition to plain text files."
  },
  {
    "objectID": "homework/Zhang yi-homework/Zhangyi(2).html",
    "href": "homework/Zhang yi-homework/Zhangyi(2).html",
    "title": "",
    "section": "",
    "text": "# %load Zhangyi(2).py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 读取 CSV 文件\ndf = pd.read_csv('plastic-waste.csv')\n\n# 清理数据：去除缺失值\ndf_cleaned = df.dropna(subset=['continent', 'plastic_waste_per_cap'])\n\n# 设置图形风格\nsns.set(style=\"whitegrid\")\n\n# 创建 FacetGrid，按 'continent' 分面\ng = sns.FacetGrid(df_cleaned, col='continent', col_wrap=3, height=4, sharey=False)\ng.map(sns.violinplot, 'plastic_waste_per_cap', color='blue')\n\n# 设置图表标题和坐标轴标签\ng.set_titles(\"{col_name} Plastic Waste Per Capita Violin Plot\")\ng.set_axis_labels(\"Plastic Waste Per Capita (kg)\", \"Density\")\ng.fig.suptitle(\"Violin Plot of Plastic Waste Per Capita by Continent\", fontsize=16)\ng.tight_layout(pad=2)\n\n# 显示图形\nplt.show()"
  },
  {
    "objectID": "homework/Zhang yi-homework/Zhangyi(4).html",
    "href": "homework/Zhang yi-homework/Zhangyi(4).html",
    "title": "",
    "section": "",
    "text": "# %load Zhangyi(4).py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 读取 CSV 文件\ndf = pd.read_csv('plastic-waste.csv')\n\n# 清理数据：去除缺失值\ndf_cleaned = df.dropna(subset=['total_pop', 'coastal_pop', 'plastic_waste_per_cap'])\n\n# 创建两个子图\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# 人均塑料垃圾与总人口的关系\nsns.scatterplot(x='total_pop', y='plastic_waste_per_cap', data=df_cleaned, ax=axes[0])\naxes[0].set_title(\"Plastic Waste Per Capita vs. Total Population\")\naxes[0].set_xlabel(\"Total Population\")\naxes[0].set_ylabel(\"Plastic Waste Per Capita (kg)\")\n\n# 人均塑料垃圾与沿海人口的关系\nsns.scatterplot(x='coastal_pop', y='plastic_waste_per_cap', data=df_cleaned, ax=axes[1])\naxes[1].set_title(\"Plastic Waste Per Capita vs. Coastal Population\")\naxes[1].set_xlabel(\"Coastal Population\")\naxes[1].set_ylabel(\"Plastic Waste Per Capita (kg)\")\n\n# 显示图形\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Group C, Zhang Yi homework1",
    "section": "",
    "text": "import pandas as pd\nurl ='https://raw.githubusercontent.com/tidyverse/datascience-box/refs/heads/main/course-materials/lab-instructions/lab-03/data/nobel.csv'\ndf = pd.read_csv(url)\nprint(df.head())\n\n   id       firstname    surname  year category  \\\n0   1  Wilhelm Conrad    Röntgen  1901  Physics   \n1   2      Hendrik A.    Lorentz  1902  Physics   \n2   3          Pieter     Zeeman  1902  Physics   \n3   4           Henri  Becquerel  1903  Physics   \n4   5          Pierre      Curie  1903  Physics   \n\n                                         affiliation       city      country  \\\n0                                  Munich University     Munich      Germany   \n1                                  Leiden University     Leiden  Netherlands   \n2                               Amsterdam University  Amsterdam  Netherlands   \n3                                École Polytechnique      Paris       France   \n4  École municipale de physique et de chimie indu...      Paris       France   \n\n    born_date   died_date  ... died_country_code overall_motivation share  \\\n0  1845-03-27  1923-02-10  ...                DE                NaN     1   \n1  1853-07-18  1928-02-04  ...                NL                NaN     2   \n2  1865-05-25  1943-10-09  ...                NL                NaN     2   \n3  1852-12-15  1908-08-25  ...                FR                NaN     2   \n4  1859-05-15  1906-04-19  ...                FR                NaN     4   \n\n                                          motivation  born_country_original  \\\n0  \"in recognition of the extraordinary services ...  Prussia (now Germany)   \n1  \"in recognition of the extraordinary service t...        the Netherlands   \n2  \"in recognition of the extraordinary service t...        the Netherlands   \n3  \"in recognition of the extraordinary services ...                 France   \n4  \"in recognition of the extraordinary services ...                 France   \n\n       born_city_original died_country_original died_city_original  \\\n0  Lennep (now Remscheid)               Germany             Munich   \n1                  Arnhem       the Netherlands                NaN   \n2              Zonnemaire       the Netherlands          Amsterdam   \n3                   Paris                France                NaN   \n4                   Paris                France              Paris   \n\n   city_original country_original  \n0         Munich          Germany  \n1         Leiden  the Netherlands  \n2      Amsterdam  the Netherlands  \n3          Paris           France  \n4          Paris           France  \n\n[5 rows x 26 columns]\n\n\n\ndf\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n0\n1\nWilhelm Conrad\nRöntgen\n1901\nPhysics\nMunich University\nMunich\nGermany\n1845-03-27\n1923-02-10\n...\nDE\nNaN\n1\n\"in recognition of the extraordinary services ...\nPrussia (now Germany)\nLennep (now Remscheid)\nGermany\nMunich\nMunich\nGermany\n\n\n1\n2\nHendrik A.\nLorentz\n1902\nPhysics\nLeiden University\nLeiden\nNetherlands\n1853-07-18\n1928-02-04\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nArnhem\nthe Netherlands\nNaN\nLeiden\nthe Netherlands\n\n\n2\n3\nPieter\nZeeman\n1902\nPhysics\nAmsterdam University\nAmsterdam\nNetherlands\n1865-05-25\n1943-10-09\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nZonnemaire\nthe Netherlands\nAmsterdam\nAmsterdam\nthe Netherlands\n\n\n3\n4\nHenri\nBecquerel\n1903\nPhysics\nÉcole Polytechnique\nParis\nFrance\n1852-12-15\n1908-08-25\n...\nFR\nNaN\n2\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nNaN\nParis\nFrance\n\n\n4\n5\nPierre\nCurie\n1903\nPhysics\nÉcole municipale de physique et de chimie indu...\nParis\nFrance\n1859-05-15\n1906-04-19\n...\nFR\nNaN\n4\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nParis\nParis\nFrance\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n931\n966\nDenis\nMukwege\n2018\nPeace\nNaN\nNaN\nNaN\n1955-03-01\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nBelgian Congo (now Democratic Republic of the ...\nBukavu\nNaN\nNaN\nNaN\nNaN\n\n\n932\n967\nNadia\nMurad\n2018\nPeace\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nIraq\nKojo\nNaN\nNaN\nNaN\nNaN\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n935 rows × 26 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 935 entries, 0 to 934\nData columns (total 26 columns):\n #   Column                 Non-Null Count  Dtype \n---  ------                 --------------  ----- \n 0   id                     935 non-null    int64 \n 1   firstname              935 non-null    object\n 2   surname                906 non-null    object\n 3   year                   935 non-null    int64 \n 4   category               935 non-null    object\n 5   affiliation            685 non-null    object\n 6   city                   680 non-null    object\n 7   country                681 non-null    object\n 8   born_date              902 non-null    object\n 9   died_date              627 non-null    object\n 10  gender                 935 non-null    object\n 11  born_city              907 non-null    object\n 12  born_country           907 non-null    object\n 13  born_country_code      907 non-null    object\n 14  died_city              608 non-null    object\n 15  died_country           614 non-null    object\n 16  died_country_code      614 non-null    object\n 17  overall_motivation     17 non-null     object\n 18  share                  935 non-null    int64 \n 19  motivation             935 non-null    object\n 20  born_country_original  907 non-null    object\n 21  born_city_original     907 non-null    object\n 22  died_country_original  614 non-null    object\n 23  died_city_original     608 non-null    object\n 24  city_original          680 non-null    object\n 25  country_original       681 non-null    object\ndtypes: int64(3), object(23)\nmemory usage: 190.1+ KB\n\n\n\ndf[(df['country'].notna())]\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n0\n1\nWilhelm Conrad\nRöntgen\n1901\nPhysics\nMunich University\nMunich\nGermany\n1845-03-27\n1923-02-10\n...\nDE\nNaN\n1\n\"in recognition of the extraordinary services ...\nPrussia (now Germany)\nLennep (now Remscheid)\nGermany\nMunich\nMunich\nGermany\n\n\n1\n2\nHendrik A.\nLorentz\n1902\nPhysics\nLeiden University\nLeiden\nNetherlands\n1853-07-18\n1928-02-04\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nArnhem\nthe Netherlands\nNaN\nLeiden\nthe Netherlands\n\n\n2\n3\nPieter\nZeeman\n1902\nPhysics\nAmsterdam University\nAmsterdam\nNetherlands\n1865-05-25\n1943-10-09\n...\nNL\nNaN\n2\n\"in recognition of the extraordinary service t...\nthe Netherlands\nZonnemaire\nthe Netherlands\nAmsterdam\nAmsterdam\nthe Netherlands\n\n\n3\n4\nHenri\nBecquerel\n1903\nPhysics\nÉcole Polytechnique\nParis\nFrance\n1852-12-15\n1908-08-25\n...\nFR\nNaN\n2\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nNaN\nParis\nFrance\n\n\n4\n5\nPierre\nCurie\n1903\nPhysics\nÉcole municipale de physique et de chimie indu...\nParis\nFrance\n1859-05-15\n1906-04-19\n...\nFR\nNaN\n4\n\"in recognition of the extraordinary services ...\nFrance\nParis\nFrance\nParis\nParis\nFrance\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n928\n963\nFrances H.\nArnold\n2018\nChemistry\nCalifornia Institute of Technology (Caltech)\nPasadena CA\nUSA\n1956-07-25\nNaN\n...\nNaN\nNaN\n2\n\"for the directed evolution of enzymes\"\nUSA\nPittsburgh PA\nNaN\nNaN\nPasadena CA\nUSA\n\n\n929\n964\nGeorge P.\nSmith\n2018\nChemistry\nUniversity of Missouri\nColumbia\nUSA\n1941-03-10\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUSA\nNorwalk CT\nNaN\nNaN\nColumbia\nUSA\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n681 rows × 26 columns\n\n\n\n\ndf[(df['died_date'].isna())]\n\n\n\n\n\n\n\n\nid\nfirstname\nsurname\nyear\ncategory\naffiliation\ncity\ncountry\nborn_date\ndied_date\n...\ndied_country_code\noverall_motivation\nshare\nmotivation\nborn_country_original\nborn_city_original\ndied_country_original\ndied_city_original\ncity_original\ncountry_original\n\n\n\n\n68\n68\nChen Ning\nYang\n1957\nPhysics\nInstitute for Advanced Study\nPrinceton NJ\nUSA\n1922-09-22\nNaN\n...\nNaN\nNaN\n2\n\"for their penetrating investigation of the so...\nChina\nHofei Anhwei\nNaN\nNaN\nPrinceton NJ\nUSA\n\n\n69\n69\nTsung-Dao\nLee\n1957\nPhysics\nColumbia University\nNew York NY\nUSA\n1926-11-24\nNaN\n...\nNaN\nNaN\n2\n\"for their penetrating investigation of the so...\nChina\nShanghai\nNaN\nNaN\nNew York NY\nUSA\n\n\n94\n95\nLeon N.\nCooper\n1972\nPhysics\nBrown University\nProvidence RI\nUSA\n1930-02-28\nNaN\n...\nNaN\nNaN\n3\n\"for their jointly developed theory of superco...\nUSA\nNew York NY\nNaN\nNaN\nProvidence RI\nUSA\n\n\n96\n97\nLeo\nEsaki\n1973\nPhysics\nIBM Thomas J. Watson Research Center\nYorktown Heights NY\nUSA\n1925-03-12\nNaN\n...\nNaN\nNaN\n4\n\"for their experimental discoveries regarding ...\nJapan\nOsaka\nNaN\nNaN\nYorktown Heights NY\nUSA\n\n\n97\n98\nIvar\nGiaever\n1973\nPhysics\nGeneral Electric Company\nSchenectady NY\nUSA\n1929-04-05\nNaN\n...\nNaN\nNaN\n4\n\"for their experimental discoveries regarding ...\nNorway\nBergen\nNaN\nNaN\nSchenectady NY\nUSA\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n930\n965\nSir Gregory P.\nWinter\n2018\nChemistry\nMRC Laboratory of Molecular Biology\nCambridge\nUnited Kingdom\n1951-04-14\nNaN\n...\nNaN\nNaN\n4\n\"for the phage display of peptides and antibod...\nUnited Kingdom\nLeicester\nNaN\nNaN\nCambridge\nUnited Kingdom\n\n\n931\n966\nDenis\nMukwege\n2018\nPeace\nNaN\nNaN\nNaN\n1955-03-01\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nBelgian Congo (now Democratic Republic of the ...\nBukavu\nNaN\nNaN\nNaN\nNaN\n\n\n932\n967\nNadia\nMurad\n2018\nPeace\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for their efforts to end the use of sexual vi...\nIraq\nKojo\nNaN\nNaN\nNaN\nNaN\n\n\n933\n968\nWilliam D.\nNordhaus\n2018\nEconomics\nYale University\nNew Haven CT\nUSA\n1941-05-31\nNaN\n...\nNaN\nNaN\n2\n\"for integrating climate change into long-run ...\nUSA\nAlbuquerque NM\nNaN\nNaN\nNew Haven CT\nUSA\n\n\n934\n969\nPaul M.\nRomer\n2018\nEconomics\nNYU Stern School of Business\nNew York NY\nUSA\nNaN\nNaN\n...\nNaN\nNaN\n2\n\"for integrating technological innovations int...\nUSA\nDenver CO\nNaN\nNaN\nNew York NY\nUSA\n\n\n\n\n308 rows × 26 columns\n\n\n\nSource: Group C, Zhang Yi homework1.ipynb"
  },
  {
    "objectID": "homework.html#prerequisites",
    "href": "homework.html#prerequisites",
    "title": "Group C, Zhang Yi homework1",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou’ll need an installation of Python and Visual Studio Code with the Python extensions to get to grips with this chapter. If you haven’t installed those yet, head back to {ref}code-preliminaries and follow the instructions there."
  },
  {
    "objectID": "homework.html#working-with-python-scripts-and-the-interactive-window",
    "href": "homework.html#working-with-python-scripts-and-the-interactive-window",
    "title": "Group C, Zhang Yi homework1",
    "section": "Working with Python scripts and the interactive window",
    "text": "Working with Python scripts and the interactive window\nAs a reminder, the figure below shows the typical layout of Visual Studio Code.\n\n\n\nA typical user view in Visual Studio Code\n\n\nWhen you create a new script (File-&gt;New File-&gt;Save as ’your_script_name.py), it will appear in the part of the screen labelled as 3.\nTo run a script, select the code you want to run, right click, and select “Run Selection/Line in Interactive Window”. You can also hit shift + enter if you set this shortcut up; if you haven’t it’s well worth doing and you can find the instructions in {ref}code-preliminaries.\nUsing the “Run Selection/Line in Interactive Window” option or using the shortcut will cause panel 5 in the above diagram (the interactive window) to appear, where you will see the code run and the outputs of your script appear.\nIf you have an issue getting the code to run in the interactive window, first check the instructions in {ref}`code-preliminaries`. If you're still having issues, it may be that Visual Studio Code isn't sure which Python to run, or where Python is on your system. To fix the latter problem, hit the \"Select kernel\" button in the top right-hand side of the interactive window.\nWhen you are first writing a script, it’s useful to be able to move back and forth between the script and the interactive window. You might execute a line of code (put the cursor on the relevant line and hit shift and enter) in the interactive window, then manually write out some code in the interactive window’s execution box (seen at the bottom of panel 5 saying “Type code here…”), and then explore some of the variables you’ve created with the variable explorer (using the button “Variables”) at the top of the interactive window.\nBut, once you’ve honed the code in your script, it’s good to make the script a complete analytical process that you are happy running end-to-end and that—for production or ‘final’ work—you would use the “Run Current File in Interactive Window” option to run all the way through. This is good practice because what is in your script is reproducible but what you’ve entered manually in the interactive window is not. And you want the outputs from your code to be reproducible and understandable by others (including future you!), but this is hard if there are undocumented extra lines of code that you only did on the fly via the interactive window’s execution box."
  },
  {
    "objectID": "homework.html#using-installed-packages-and-modules",
    "href": "homework.html#using-installed-packages-and-modules",
    "title": "Group C, Zhang Yi homework1",
    "section": "Using installed packages and modules",
    "text": "Using installed packages and modules\nWe already saw how to install packages in {ref}code-preliminaries. If you forgot, look back at how to do this now. In short, packages are installed using the command line or, on Windows, the Anaconda prompt. With either of these open, type conda install packagename and hit enter to both search for and install the package you need.\nWhat about using a package that you’ve installed? That’s what we’ll look at now.\nLet’s see an example of using the powerful numerical library numpy. There are different ways to import packages to use within a script or notebook; you can import the entire package in one go or just import the functions you need (if you know their names). When an entire package is imported, you can give it any name you like and the convention for numpy is to import it as the shortened ‘np’. All of the functions and methods of the package can be accessed by typing np followed by . and then typing the function name. This convention of importing packages with a given name makes your code easier to read, because you know exactly which package is doing what, and avoids any conflicts when functions from different packages have the same name.\nAs well as demonstrating importing the whole package for numpy, the example below shows importing just one specific function from numpy, inv, which does matrix inversion. Note that because inv was imported separately it can be used without an np prefix.\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\n\nimport numpy as np\nfrom numpy.linalg import inv\n\nmatrix = np.array([[4.0, 2.0, 4.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n\nprint(\"Matrix:\")\nprint(matrix)\n\ninv_mat = inv(matrix)\nprint(\"Inverse:\")\nprint(inv_mat)\n\nMatrix:\n[[4. 2. 4.]\n [4. 5. 6.]\n [7. 8. 9.]]\nInverse:\n[[ 0.25       -1.16666667  0.66666667]\n [-0.5        -0.66666667  0.66666667]\n [ 0.25        1.5        -1.        ]]\n\n\nWe could have imported all of numpy and it used it without extension using from numpy import * but this is considered bad practice as it fills our ‘namespace’ with function names that might clash with other packages and it’s less easy to read because you don’t know which function came from which package (one of Python’s mantras is “explicit is better than implict”). However, some packages are designed to be used like this, so, for example, you will see from lets_plot import * in this book.\nIf you want to check what packages you have installed in your Python environment, run `conda list` on your computer's command line (aka the *terminal* or *command prompt*).\nSometimes you might forget what a function you have imported does! Or at least, you might not be sure what all of the optional arguments are. In Visual Studio Code, you can just hover your cursor over the name of the function and a box will come up that tells you everything you need to know about it. This box is auto-generated by doc-strings; information that is written in text just under a function’s definition (def statement).\nAn alternative way to see what a function does is to use a wonderful package called rich that does many things including providing an inspect() function. You will need to use pip to install rich by running pip install rich on the command line. Here’s an example of using rich’s inpsect method on the inv() function we imported above (methods=True reports all of the functionality of inv()):\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\n\nfrom rich import inspect\n\ninspect(inv, help=True)\n\n╭─────────────── &lt;function inv at 0x000002308AF6F560&gt; ────────────────╮\n│ def inv(a):                                                         │\n│                                                                     │\n│ Compute the (multiplicative) inverse of a matrix.                   │\n│                                                                     │\n│ Given a square matrix `a`, return the matrix `ainv` satisfying      │\n│ ``dot(a, ainv) = dot(ainv, a) = eye(a.shape[0])``.                  │\n│                                                                     │\n│ Parameters                                                          │\n│ ----------                                                          │\n│ a : (..., M, M) array_like                                          │\n│     Matrix to be inverted.                                          │\n│                                                                     │\n│ Returns                                                             │\n│ -------                                                             │\n│ ainv : (..., M, M) ndarray or matrix                                │\n│     (Multiplicative) inverse of the matrix `a`.                     │\n│                                                                     │\n│ Raises                                                              │\n│ ------                                                              │\n│ LinAlgError                                                         │\n│     If `a` is not square or inversion fails.                        │\n│                                                                     │\n│ See Also                                                            │\n│ --------                                                            │\n│ scipy.linalg.inv : Similar function in SciPy.                       │\n│                                                                     │\n│ Notes                                                               │\n│ -----                                                               │\n│                                                                     │\n│ .. versionadded:: 1.8.0                                             │\n│                                                                     │\n│ Broadcasting rules apply, see the `numpy.linalg` documentation for  │\n│ details.                                                            │\n│                                                                     │\n│ Examples                                                            │\n│ --------                                                            │\n│ &gt;&gt;&gt; from numpy.linalg import inv                                    │\n│ &gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])                              │\n│ &gt;&gt;&gt; ainv = inv(a)                                                   │\n│ &gt;&gt;&gt; np.allclose(np.dot(a, ainv), np.eye(2))                         │\n│ True                                                                │\n│ &gt;&gt;&gt; np.allclose(np.dot(ainv, a), np.eye(2))                         │\n│ True                                                                │\n│                                                                     │\n│ If a is a matrix object, then the return value is a matrix as well: │\n│                                                                     │\n│ &gt;&gt;&gt; ainv = inv(np.matrix(a))                                        │\n│ &gt;&gt;&gt; ainv                                                            │\n│ matrix([[-2. ,  1. ],                                               │\n│         [ 1.5, -0.5]])                                              │\n│                                                                     │\n│ Inverses of several matrices can be computed at once:               │\n│                                                                     │\n│ &gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])          │\n│ &gt;&gt;&gt; inv(a)                                                          │\n│ array([[[-2.  ,  1.  ],                                             │\n│         [ 1.5 , -0.5 ]],                                            │\n│        [[-1.25,  0.75],                                             │\n│         [ 0.75, -0.25]]])                                           │\n│                                                                     │\n│ 34 attribute(s) not shown. Run inspect(inspect) for options.        │\n╰─────────────────────────────────────────────────────────────────────╯\n\n\n\ndpvshwsflwfl Exercise Write a code block that imports the **numpy** function `numpy.linalg.det()` as `det()`. Run `inspect()` on it. Find the determinant of `[[4, 3], [1, 7]]`.\n\nModules\nSometimes, you will want to call in some code from a different script that you wrote (rather than from a package provided by someone else). Imagine you have several scripts with code in, a, b, and c, all of which need to use the same underlying function that you have written. What do you do? (Note that “script with code in” is just a text file that has a .py extension and contains code.)\nA central tenet of good coding is that you do not repeat yourself. Therefore, a bad solution to this problem would be to copy and paste the same code into all three of the scripts. A good solution is to write the code that’s need just once in a separate ‘utility’ script and have the other scripts import that one function. This also adheres to another important programming principle: that of writing modular code.\nThis schematic shows the kind of situation we’re talking about:\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib_inline.backend_inline\n\n# Plot settings\nplt.style.use(\n    \"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\"\n)\nmatplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n\n\ngraph = nx.DiGraph()\ngraph.add_edges_from(\n    [\n        (\"Utility script\", \"code file a\"),\n        (\"Utility script\", \"code file b\"),\n        (\"code file a\", \"code file c\"),\n        (\"code file b\", \"code file c\"),\n        (\"Utility script\", \"code file c\"),\n    ]\n)\ncolour_node = \"#AFCBFF\"\nfixed_pos = nx.spring_layout(graph, seed=100)\nnx.draw(graph, pos=fixed_pos, with_labels=True, node_size=6000, node_color=colour_node)\nextent = 1.4\nplt.xlim(-extent, extent)\nplt.ylim(-extent, extent)\nplt.show();\n\n\n\n\n\n\n\n\nHow can we give code files a, b, and c access to the functions etc in the “Utility script”? We would define a file ‘utilities.py’ that had the following function in that we would like to use in the other code files:\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\nThen, in ‘code_script_a.py’, we would write:\n\nimport utilities as utils\n\nprint(utils.really_useful_func(20))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 import utilities as utils\n      3 print(utils.really_useful_func(20))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAn alternative is to just import the function we want, with the name we want:\n\nfrom utilities import really_useful_func as ru_fn\n\nprint(ru_fn(30))\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 from utilities import really_useful_func as ru_fn\n      3 print(ru_fn(30))\n\nModuleNotFoundError: No module named 'utilities'\n\n\n\nAnother important example is the case where you want to run ‘utilities.py’ as a standalone script, but still want to borrow functions from it to run in other scripts. There’s a way to do this. Let’s change utilities.py to\n# Contents of utilities.py file\ndef really_useful_func(number):\n    return number*10\n\n\ndef default_func():\n    print('Script has run')\n\n\nif __name__ == '__main__':\n    default_func()\nWhat this says is that if we call ‘utilities.py’ from the command line, eg\npython utilities.py\nIt will return Script has run because, by executing the script alone, we are asking for anything in the main block defined at the end of the file to be run. But we can still import anything from utilities into other scripts as before–and in that case it is not the main script, but an import, and so the main block will not be executed by default.\nYou can important several functions at once from a module (aka another script file) like this:\nfrom utilities import really_useful_func, default_func\ndpvshwsflwfl Exercise Write your own `utilities.py` that has a `super_useful_func` that accepts a number and returns the number divided by 10. In another script, `main.py`, try a) importing all of utilities and running `super_useful_func` on a number and, b), importing just `super_useful_func` from utilities and running it on a number."
  },
  {
    "objectID": "homework.html#reading-and-writing-files",
    "href": "homework.html#reading-and-writing-files",
    "title": "Group C, Zhang Yi homework1",
    "section": "Reading and writing files",
    "text": "Reading and writing files\nAlthough most applications in economics will use the pandas package to read and write tabular data, it’s sometimes useful to know how to read and write arbitrary files using the built-in Python libraries too. To open a file\nopen('filename', mode)\nwhere mode could be r for read, a for append, w for write, and x to create a file. Create a file called text_example.txt and write a single line in it, ‘hello world’. To open the file and print the text, use:\nwith open('text_example.txt') as f:\n    text_in = f.read()\n\nprint(text_in)\n'hello world!\\n'\n\\n is the new line character. Now let’s try adding a line to the file:\nwith open('text_example.txt', 'a') as f:\n    f.write('this is another line\\n')\nWriting and reading files using the with command is a quick and convenient shorthand for the less concise open, action, close pattern. For example, the above example can also be written as:\nf = open('text_example.txt', 'a')\nf.write('this is another line\\n')\nf.close()\nAlthough this short example shows opening and writing a text file, this approach can be used to edit a wide range of file extensions including .json, .xml, .csv, .tsv, and many more, including binary files in addition to plain text files."
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "实验室",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。\n\n\n\ndf = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。\n\n\n\nmonth = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n\n\n\ndf[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();\n\n\n\ntemp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")\n\n\n\n# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")\n\n\n\ntemp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)\n\n\n\ndf_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "labs.html#演练1.1",
    "href": "labs.html#演练1.1",
    "title": "实验室",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n## You don't need to use these settings yourself,\n## they are just here to make the charts look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndf = pd.read_csv(\n    \"https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv\",\n    skiprows=1,\n    na_values=\"***\",\n)\ndf.head()\ndf.info()\n温度异常是指相对于某个参考时期的平均温度的偏离情况。它是一种衡量当前温度与长期平均温度差值的方式，重点在于体现温度的变化情况，而不是实际的温度数值。温度异常有助于突出长期的温度变化趋势。对于研究气候变化这样的长期过程，关注温度相对于历史平均值的变化更有意义。它可以过滤掉一些短期的、局部的温度波动，让研究人员更准确地把握地球气候系统是在变暖还是变冷这样的宏观趋势。"
  },
  {
    "objectID": "labs.html#演练1.2",
    "href": "labs.html#演练1.2",
    "title": "实验室",
    "section": "",
    "text": "df = df.set_index(\"Year\")\ndf.head()\ndf.tail()\nfig, ax = plt.subplots()\nax.plot(df.index, df[\"Jan\"])\nax.set_ylabel(\"y label\")\nax.set_xlabel(\"x label\")\nax.set_title(\"title\")\nplt.show()\nmonth = \"Jan\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.66, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average temperature anomaly in {month} \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");\n问题 2 至 4 (a)中的图表对温度和时间之间的关系可以发现，在1880年到1930年之间，每年一月份的气温相比于1951-1980年平均气温要低，后续的关系呈正相关关系，即随着时间的增长气温也随之增长。"
  },
  {
    "objectID": "labs.html#演练1.3",
    "href": "labs.html#演练1.3",
    "title": "实验室",
    "section": "",
    "text": "month = \"J-D\"\nfig, ax = plt.subplots()\nax.axhline(0, color=\"orange\")\nax.annotate(\"1951—1980 average\", xy=(0.68, -0.2), xycoords=(\"figure fraction\", \"data\"))\ndf[month].plot(ax=ax)\nax.set_title(\n    f\"Average annual temperature anomaly in \\n in the northern hemisphere (1880—{df.index.max()})\"\n)\nax.set_ylabel(\"Annual temperature anomalies\");"
  },
  {
    "objectID": "labs.html#演练1.4",
    "href": "labs.html#演练1.4",
    "title": "实验室",
    "section": "",
    "text": "df[\"Period\"] = pd.cut(\n    df.index,\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\ndf[\"Period\"].tail(20)\nlist_of_months = [\"Jun\", \"Jul\", \"Aug\"]\ndf[list_of_months].stack().head()\nfig, axes = plt.subplots(ncols=3, figsize=(9, 4), sharex=True, sharey=True)\nfor ax, period in zip(axes, df[\"Period\"].dropna().unique()):\n    df.loc[df[\"Period\"] == period, list_of_months].stack().hist(ax=ax)\n    ax.set_title(period)\nplt.suptitle(\"Histogram of temperature anomalies\")\naxes[1].set_xlabel(\"Summer temperature distribution\")\nplt.tight_layout();"
  },
  {
    "objectID": "labs.html#演练1.5",
    "href": "labs.html#演练1.5",
    "title": "实验室",
    "section": "",
    "text": "temp_all_months = df.loc[(df.index &gt;= 1951) & (df.index &lt;= 1980), \"Jan\":\"Dec\"]\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\ntemp_all_months\n\nquantiles = [0.3, 0.7]\nlist_of_percentiles = np.quantile(temp_all_months[\"values\"], q=quantiles)\n\nprint(f\"The cold threshold of {quantiles[0]*100}% is {list_of_percentiles[0]}\")\nprint(f\"The hot threshold of {quantiles[1]*100}% is {list_of_percentiles[1]}\")"
  },
  {
    "objectID": "labs.html#演练1.6",
    "href": "labs.html#演练1.6",
    "title": "实验室",
    "section": "",
    "text": "# Create a variable that has years 1981 to 2010, and months Jan to Dec (inclusive)\ntemp_all_months = df.loc[(df.index &gt;= 1981) & (df.index &lt;= 2010), \"Jan\":\"Dec\"]\n# Put all the data in stacked format and give the new columns sensible names\ntemp_all_months = (\n    temp_all_months.stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"month\", 0: \"values\"})\n)\n# Take a look at the start of this data data:\ntemp_all_months.head()\nentries_less_than_q30 = temp_all_months[\"values\"] &lt; list_of_percentiles[0]\nproportion_under_q30 = entries_less_than_q30.mean()\nprint(\n    f\"The proportion under {list_of_percentiles[0]} is {proportion_under_q30*100:.2f}%\"\n)\nproportion_over_q70 = (temp_all_months[\"values\"] &gt; list_of_percentiles[1]).mean()\nprint(f\"The proportion over {list_of_percentiles[1]} is {proportion_over_q70*100:.2f}%\")"
  },
  {
    "objectID": "labs.html#演练1.7",
    "href": "labs.html#演练1.7",
    "title": "实验室",
    "section": "",
    "text": "temp_all_months = (\n    df.loc[:, \"DJF\":\"SON\"]\n    .stack()\n    .reset_index()\n    .rename(columns={\"level_1\": \"Season\", 0: \"Values\"})\n)\ntemp_all_months[\"Period\"] = pd.cut(\n    temp_all_months[\"Year\"],\n    bins=[1921, 1950, 1980, 2010],\n    labels=[\"1921—1950\", \"1951—1980\", \"1981—2010\"],\n    ordered=True,\n)\n# Take a look at a cut of the data using `.iloc`, which provides position\ntemp_all_months.iloc[-135:-125]\ngrp_mean_var = temp_all_months.groupby([\"Season\", \"Period\"])[\"Values\"].agg(\n    [np.mean, np.var]\n)\ngrp_mean_var\nmin_year = 1880\n(\n    ggplot(temp_all_months, aes(x=\"Year\", y=\"Values\", color=\"Season\"))\n    + geom_abline(slope=0, color=\"black\", size=1)\n    + geom_line(size=1)\n    + labs(\n        title=f\"Average annual temperature anomaly in \\n in the northern hemisphere ({min_year}—{temp_all_months['Year'].max()})\",\n        y=\"Annual temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n    + geom_text(\n        x=min_year, y=0.1, label=\"1951—1980 average\", hjust=\"left\", color=\"black\"\n    )\n)"
  },
  {
    "objectID": "labs.html#演练1.8",
    "href": "labs.html#演练1.8",
    "title": "实验室",
    "section": "",
    "text": "df_co2 = pd.read_excel(\"data_co2.xlsx\")\ndf_co2.head()\ndf_co2_june = df_co2.loc[df_co2[\"Month\"] == 6]\ndf_co2_june.head()\ndf_temp_co2 = pd.merge(df_co2_june, df, on=\"Year\")\ndf_temp_co2[[\"Year\", \"Jun\", \"Trend\"]].head()\n(\n    ggplot(df_temp_co2, aes(x=\"Jun\", y=\"Trend\"))\n    + geom_point(color=\"black\", size=3)\n    + labs(\n        title=\"Scatterplot of temperature anomalies vs carbon dioxide emissions\",\n        y=\"Carbon dioxide levels (trend, mole fraction)\",\n        x=\"Temperature anomaly (degrees Celsius)\",\n    )\n)\ndf_temp_co2[[\"Jun\", \"Trend\"]].corr(method=\"pearson\")\n(\n    ggplot(df_temp_co2, aes(x=\"Year\", y=\"Jun\"))\n    + geom_line(size=1)\n    + labs(\n        title=\"June temperature anomalies\",\n    )\n    + scale_x_continuous(format=\"d\")\n)\nbase_plot = ggplot(df_temp_co2) + scale_x_continuous(format=\"d\")\nplot_p = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Jun\"), size=1)\n    + labs(title=\"June temperature anomalies\")\n)\nplot_q = (\n    base_plot\n    + geom_line(aes(x=\"Year\", y=\"Trend\"), size=1)\n    + labs(title=\"Carbon dioxide emissions\")\n)\ngggrid([plot_p, plot_q], ncol=2)\n从上述图标可以看出，年份与CO_2的关系呈正相关关系，同时业余气温变化呈正相关关系，而且从它们的变化曲线可以看出均呈指数型增长，因此气温变化异常与二氧化碳有关系。"
  },
  {
    "objectID": "labs.html#演练2.1",
    "href": "labs.html#演练2.1",
    "title": "实验室",
    "section": "演练2.1",
    "text": "演练2.1\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");"
  },
  {
    "objectID": "labs.html#演练2.2",
    "href": "labs.html#演练2.2",
    "title": "实验室",
    "section": "演练2.2",
    "text": "演练2.2\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\ndata_n.info()\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")"
  },
  {
    "objectID": "labs.html#演练2.3",
    "href": "labs.html#演练2.3",
    "title": "实验室",
    "section": "演练2.3",
    "text": "演练2.3\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();"
  },
  {
    "objectID": "labs.html#演练2.4",
    "href": "labs.html#演练2.4",
    "title": "实验室",
    "section": "演练2.4",
    "text": "演练2.4\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);"
  },
  {
    "objectID": "labs.html#演练2.5",
    "href": "labs.html#演练2.5",
    "title": "实验室",
    "section": "演练2.5",
    "text": "演练2.5\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();"
  },
  {
    "objectID": "labs.html#演练2.6",
    "href": "labs.html#演练2.6",
    "title": "实验室",
    "section": "演练2.6",
    "text": "演练2.6\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();"
  },
  {
    "objectID": "labs.html#演练2.7",
    "href": "labs.html#演练2.7",
    "title": "实验室",
    "section": "演练2.7",
    "text": "演练2.7\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n.loc[[1, 10], :].round(2)\nsumm_p.loc[[1, 10], :].round(2)"
  },
  {
    "objectID": "labs.html#演练2.8",
    "href": "labs.html#演练2.8",
    "title": "实验室",
    "section": "演练2.8",
    "text": "演练2.8\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)"
  },
  {
    "objectID": "labs.html#演练3.1",
    "href": "labs.html#演练3.1",
    "title": "实验室",
    "section": "演练3.1",
    "text": "演练3.1\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport textwrap\npd.read_csv(\n    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n)\nimport requests\n\nurl = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n\n# Get the data from the ONS API:\njson_data = requests.get(url).json()\n\n# Prep the data for a quick plot\ntitle = json_data[\"description\"][\"title\"]\ndf = (\n    pd.DataFrame(pd.json_normalize(json_data[\"months\"]))\n    .assign(\n        date=lambda x: pd.to_datetime(x[\"date\"]),\n        value=lambda x: pd.to_numeric(x[\"value\"]),\n    )\n    .set_index(\"date\")\n)\n\ndf[\"value\"].plot(title=title, ylim=(0, df[\"value\"].max() * 1.2), lw=3.0);\nfrom pandas_datareader import wb\ndf = wb.download(\n    indicator=\"EN.ATM.CO2E.PC\",\n    country=[\"US\", \"CHN\", \"IND\", \"Z4\", \"Z7\"],\n    start=2017,\n    end=2017,\n)\n# remove country as index for ease of plotting with seaborn\ndf = df.reset_index()\n# wrap long country names\ndf[\"country\"] = df[\"country\"].apply(lambda x: textwrap.fill(x, 10))\n# order based on size\ndf = df.sort_values(\"EN.ATM.CO2E.PC\")\ndf.head()\nimport seaborn as sns\n\nfig, ax = plt.subplots()\nsns.barplot(x=\"country\", y=\"EN.ATM.CO2E.PC\", data=df.reset_index(), ax=ax)\nax.set_title(r\"CO$_2$ (metric tons per capita)\", loc=\"right\")\nplt.suptitle(\"The USA leads the world on per-capita emissions\", y=1.01)\nfor key, spine in ax.spines.items():\n    spine.set_visible(False)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\")\nax.yaxis.tick_right()\nplt.show()\nimport pandasdmx as pdmx\n# Tell pdmx we want OECD data\noecd = pdmx.Request(\"OECD\")\n# Set out everything about the request in the format specified by the OECD API\ndata = oecd.data(\n    resource_id=\"PDB_LV\",\n    key=\"GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010\",\n).to_pandas()\n\ndf = pd.DataFrame(data).reset_index()\ndf.head()\nurl = \"http://aeturrell.com/research\"\npage = requests.get(url)\npage.text[:300]\nsoup = BeautifulSoup(page.text, \"html.parser\")\nprint(soup.prettify()[60000:60500])\n# Get all paragraphs\nall_paras = soup.find_all(\"p\")\n# Just show one of the paras\nall_paras[1]\nall_paras[1].text\nprojects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\nprojects = [x.text.strip() for x in projects]\nprojects[:4]\nstart, stop = 0, 50\nroot_url = \"www.codingforeconomists.com/page=\"\ninfo_on_pages = [scraper(root_url + str(i)) for i in range(start, stop)]\ndf_list = pd.read_html(\n    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n)\n# Retrieve first and only entry from list of dataframes\ndf = df_list[0]\ndf.head()\nimport pdftotext\nfrom pathlib import Path\n\n# Download the pdf_with_table.pdf file from\n# https://github.com/aeturrell/coding-for-economists/blob/main/data/pdf_with_table.pdf\n# and put it in a subfolder called data before running the next line\n\n# Load the PDF\nwith open(Path(\"data/pdf_with_table.pdf\"), \"rb\") as f:\n    pdf = pdftotext.PDF(f)\n\n# Read all the text into one string; print a chunk of the string\nprint(\"\\n\\n\".join(pdf)[:220])\nimport camelot\n# Grab the pdf\ntables = camelot.read_pdf(os.path.join('data', 'pdf_with_table.pdf'))\nimport textract\ntext = textract.process(Path('path/to/file.extension'))"
  },
  {
    "objectID": "labs.html#演练3.2",
    "href": "labs.html#演练3.2",
    "title": "实验室",
    "section": "演练3.2",
    "text": "演练3.2\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nheaders = {\n    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"\n}\nresponse = requests.get(url,headers=headers)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.find_all('div',class_=\"sc-300a8231-0 gTnHyA cli-children\")\nratings = soup.find_all(\"span\",class_=\"ipc-rating-star--rating\")\nlist = []\n\nfor index in range(0, len(movies)):\n    \n    movie_string = movies[index].find(\"h3\",class_='ipc-title__text').get_text()\n    movie_title = movie_string.split(\".\")[1]\n    place = movie_string.split(\".\")[0]\n    year = movies[index].find(\"span\",class_='sc-300a8231-7 eaXxft cli-title-metadata-item').get_text()\n    \n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index].get_text(),\n            \"year\": year,\n            }\n    list.append(data)\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['rating'])\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)"
  },
  {
    "objectID": "labs.html#演练3.3",
    "href": "labs.html#演练3.3",
    "title": "实验室",
    "section": "演练3.3",
    "text": "演练3.3\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\n# 提取电影名称、描述、评分和评价人数\nmovies = []\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\nfor page in range(10):\n    # 定义请求的 URL 和 headers\n    url = f\"https://movie.douban.com/top250?start={25 * page}&filter=\"\n    \n    # 发送 GET 请求\n    response = requests.get(url, headers=headers)\n    response.encoding = 'utf-8'  # 设置编码方式\n    html_content = response.text  # 获取网页的 HTML 内容\n    \n    # 使用 Beautiful Soup 解析 HTML\n    soup = BeautifulSoup(html_content, 'html.parser')\n    \n    \n    for item in soup.find_all('div', class_='item'):\n        title = item.find('span', class_='title').get_text()  # 电影名称\n        description = item.find('span', class_='inq')  # 电影描述\n        rating = item.find('span', class_='rating_num').get_text()  # 评分\n        votes = item.find('div', class_='star').find_all('span')[3].get_text()  # 评价人数\n        \n        # 如果没有描述，将其置为空字符串\n        if description:\n            description = description.get_text()\n        else:\n            description = ''\n        \n        movie = {\n            \"title\": title,\n            \"description\": description,\n            \"rating\": rating,\n            \"votes\": votes.replace('人评价', '').strip()\n        }\n        movies.append(movie)\n    break\n \n# 将数据保存到 CSV 文件\nwith open('douban_top250.csv', 'w', newline='', encoding='utf-8') as csvfile:\n    fieldnames = ['title', 'description', 'rating', 'votes']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n \n    writer.writeheader()  # 写入表头\n    for movie in movies:\n        writer.writerow(movie)  # 写入每一行数据\n \nprint(\"数据已成功保存到 douban_top250.csv\")\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei']\n\n# 读取CSV数据\nfile_path = 'douban_top250.csv'  # 确保路径正确\ndata = pd.read_csv(file_path)\n\n# 根据评分展示Top 10电影\ntop10_rating = data.nlargest(10, 'rating')  # 取评分最高的前10部电影\n\nplt.figure(figsize=(10, 6))\nplt.barh(top10_rating['title'], top10_rating['rating'], color='skyblue')\nplt.xlabel('Rating')\nplt.title('Top 10 Movies by Rating')\nplt.gca().invert_yaxis()  # 翻转Y轴，使排名靠前的电影显示在顶部\nplt.show()\n# 评分与投票数的散点图\nplt.figure(figsize=(10, 6))\nplt.scatter(data['votes'], data['rating'], alpha=0.7, color='coral')\nplt.title('Relationship between Votes and Rating')\nplt.xlabel('Number of Votes')\nplt.ylabel('Rating')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "practice/practice2.html",
    "href": "practice/practice2.html",
    "title": "演练2.1",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport pingouin as pg\nfrom lets_plot import *\n\n\nLetsPlot.setup_html(no_js=True)\n\n\n### You don't need to use these settings yourself\n### — they are just here to make the book look nicer!\n# Set the plot style for prettier charts:\nplt.style.use(\n\n    \"https://raw.githubusercontent.com/aeturrell/core_python/main/plot_style.txt\"\n)\ndata = {\n    \"Copenhagen\": [14.1, 14.1, 13.7, 12.9, 12.3, 11.7, 10.8, 10.6, 9.8, 5.3],\n    \"Dniprop\": [11.0, 12.6, 12.1, 11.2, 11.3, 10.5, 9.5, 10.3, 9.0, 8.7],\n    \"Minsk\": [12.8, 12.3, 12.6, 12.3, 11.8, 9.9, 9.9, 8.4, 8.3, 6.9],\n}\n\n\ndf = pd.DataFrame.from_dict(data)\ndf.head()\n\n\n\n\n\n\n\n\nCopenhagen\nDniprop\nMinsk\n\n\n\n\n0\n14.1\n11.0\n12.8\n\n\n1\n14.1\n12.6\n12.3\n\n\n2\n13.7\n12.1\n12.6\n\n\n3\n12.9\n11.2\n12.3\n\n\n4\n12.3\n11.3\n11.8\nfig, ax = plt.subplots()\ndf.plot(ax=ax)\nax.set_title(\"Average contributions to the public goods game: Without punishment\")\nax.set_ylabel(\"Average contribution\")\nax.set_xlabel(\"Round\");"
  },
  {
    "objectID": "practice/practice2.html#演练2.2",
    "href": "practice/practice2.html#演练2.2",
    "title": "演练2.1",
    "section": "演练2.2",
    "text": "演练2.2\n\ndata_np = pd.read_excel(\n    \"data/doing-economics-datafile-working-in-excel-project-2.xlsx\",\n    usecols=\"A:Q\",\n    header=1,\n    index_col=\"Period\",\n)\ndata_n = data_np.iloc[:10, :].copy()\ndata_p = data_np.iloc[14:24, :].copy()\n\n\ntest_data = {\n    \"City A\": [14.1, 14.1, 13.7],\n    \"City B\": [11.0, 12.6, 12.1],\n}\n\n\n# Original dataframe\ntest_df = pd.DataFrame.from_dict(test_data)\n# A copy of the dataframe\ntest_copy = test_df.copy()\n# A pointer to the dataframe\ntest_pointer = test_df\n\n\ntest_pointer.iloc[1, 1] = 99\n\n\nprint(\"test_df=\")\nprint(f\"{test_df}\\n\")\nprint(\"test_copy=\")\nprint(f\"{test_copy}\\n\")\n\ntest_df=\n   City A  City B\n0    14.1    11.0\n1    14.1    99.0\n2    13.7    12.1\n\ntest_copy=\n   City A  City B\n0    14.1    11.0\n1    14.1    12.6\n2    13.7    12.1\n\n\n\n\ndata_n.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 10 entries, 1 to 10\nData columns (total 16 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   Copenhagen       10 non-null     object\n 1   Dnipropetrovs’k  10 non-null     object\n 2   Minsk            10 non-null     object\n 3   St. Gallen       10 non-null     object\n 4   Muscat           10 non-null     object\n 5   Samara           10 non-null     object\n 6   Zurich           10 non-null     object\n 7   Boston           10 non-null     object\n 8   Bonn             10 non-null     object\n 9   Chengdu          10 non-null     object\n 10  Seoul            10 non-null     object\n 11  Riyadh           10 non-null     object\n 12  Nottingham       10 non-null     object\n 13  Athens           10 non-null     object\n 14  Istanbul         10 non-null     object\n 15  Melbourne        10 non-null     object\ndtypes: object(16)\nmemory usage: 1.3+ KB\n\n\n\ndata_n = data_n.astype(\"double\")\ndata_p = data_p.astype(\"double\")"
  },
  {
    "objectID": "practice/practice2.html#演练2.3",
    "href": "practice/practice2.html#演练2.3",
    "title": "演练2.1",
    "section": "演练2.3",
    "text": "演练2.3\n\nmean_n_c = data_n.mean(axis=1)\nmean_p_c = data_p.agg(np.mean, axis=1)\n\n\nfig, ax = plt.subplots()\nmean_n_c.plot(ax=ax, label=\"Without punishment\")\nmean_p_c.plot(ax=ax, label=\"With punishment\")\nax.set_title(\"Average contributions to the public goods game\")\nax.set_ylabel(\"Average contribution\")\nax.legend();"
  },
  {
    "objectID": "practice/practice2.html#演练2.4",
    "href": "practice/practice2.html#演练2.4",
    "title": "演练2.1",
    "section": "演练2.4",
    "text": "演练2.4\n\npartial_names_list = [\"F. Kennedy\", \"Lennon\", \"Maynard Keynes\", \"Wayne\"]\n[\"John \" + name for name in partial_names_list]\n\n['John F. Kennedy', 'John Lennon', 'John Maynard Keynes', 'John Wayne']\n\n\n\n# Create new dataframe with bars in\ncompare_grps = pd.DataFrame(\n    [mean_n_c.loc[[1, 10]], mean_p_c.loc[[1, 10]]],\n    index=[\"Without punishment\", \"With punishment\"],\n)\n# Rename columns to have 'round' in them\ncompare_grps.columns = [\"Round \" + str(i) for i in compare_grps.columns]\n# Swap the column and index variables around with the transpose function, ready for plotting (.T is transpose)\ncompare_grps = compare_grps.T\n# Make a bar chart\ncompare_grps.plot.bar(rot=0);"
  },
  {
    "objectID": "practice/practice2.html#演练2.5",
    "href": "practice/practice2.html#演练2.5",
    "title": "演练2.1",
    "section": "演练2.5",
    "text": "演练2.5\n\nn_c = data_n.agg([\"std\", \"var\", \"mean\"], 1)\nn_c\n\n\n\n\n\n\n\n\nstd\nvar\nmean\n\n\n\n\n1\n2.020724\n4.083325\n10.578313\n\n\n2\n2.238129\n5.009220\n10.628398\n\n\n3\n2.329569\n5.426891\n10.407079\n\n\n4\n2.068213\n4.277504\n9.813033\n\n\n5\n2.108329\n4.445049\n9.305433\n\n\n6\n2.240881\n5.021549\n8.454844\n\n\n7\n2.136614\n4.565117\n7.837568\n\n\n8\n2.349442\n5.519880\n7.376388\n\n\n9\n2.413845\n5.826645\n6.392985\n\n\n10\n2.187126\n4.783520\n4.383769\n\n\n\n\n\n\n\n\np_c = data_p.agg([\"std\", \"var\", \"mean\"], 1)\n\n\nfig, ax = plt.subplots()\nn_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 standard deviations\n(n_c[\"mean\"] + 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 standard deviations\n(n_c[\"mean\"] - 2 * n_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_n.columns)):\n    ax.scatter(x=data_n.index, y=data_n.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game without punishment\")\nplt.show();\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\np_c[\"mean\"].plot(ax=ax, label=\"mean\")\n# mean + 2 sd\n(p_c[\"mean\"] + 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"±2 s.d.\")\n# mean - 2 sd\n(p_c[\"mean\"] - 2 * p_c[\"std\"]).plot(ax=ax, ylim=(0, None), color=\"red\", label=\"\")\nfor i in range(len(data_p.columns)):\n    ax.scatter(x=data_p.index, y=data_p.iloc[:, i], color=\"k\", alpha=0.3)\nax.legend()\nax.set_ylabel(\"Average contribution\")\nax.set_title(\"Contribution to public goods game with punishment\")\nplt.show();"
  },
  {
    "objectID": "practice/practice2.html#演练2.6",
    "href": "practice/practice2.html#演练2.6",
    "title": "演练2.1",
    "section": "演练2.6",
    "text": "演练2.6\n\ndata_p.apply(lambda x: x.max() - x.min(), axis=1)\n\nPeriod\n1     10.199675\n2     12.185065\n3     12.689935\n4     12.625000\n5     12.140375\n6     12.827541\n7     13.098931\n8     13.482621\n9     13.496754\n10    11.307360\ndtype: float64\n\n\n\n# A lambda function accepting three inputs, a, b, and c, and calculating the sum of the squares\ntest_function = lambda a, b, c: a**2 + b**2 + c**2\n\n\n# Now we apply the function by handing over (in parenthesis) the following inputs: a=3, b=4 and c=5\ntest_function(3, 4, 5)\n\n50\n\n\n\nrange_function = lambda x: x.max() - x.min()\nrange_p = data_p.apply(range_function, axis=1)\nrange_n = data_n.apply(range_function, axis=1)\n\n\nfig, ax = plt.subplots()\nrange_p.plot(ax=ax, label=\"With punishment\")\nrange_n.plot(ax=ax, label=\"Without punishment\")\nax.set_ylim(0, None)\nax.legend()\nax.set_title(\"Range of contributions to the public goods game\")\nplt.show();"
  },
  {
    "objectID": "practice/practice2.html#演练2.7",
    "href": "practice/practice2.html#演练2.7",
    "title": "演练2.1",
    "section": "演练2.7",
    "text": "演练2.7\n\nfuncs_to_apply = [range_function, \"max\", \"min\", \"std\", \"mean\"]\nsumm_p = data_p.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\nsumm_n = data_n.apply(funcs_to_apply, axis=1).rename(columns={\"&lt;lambda&gt;\": \"range\"})\n\n\nsumm_n.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\n\n\n1\n6.14\n14.10\n7.96\n2.02\n10.58\n\n\n10\n7.38\n8.68\n1.30\n2.19\n4.38\n\n\n\n\n\n\n\n\nsumm_p.loc[[1, 10], :].round(2)\n\n\n\n\n\n\n\n\nrange\nmax\nmin\nstd\nmean\n\n\n\n\n1\n10.20\n16.02\n5.82\n3.21\n10.64\n\n\n10\n11.31\n17.51\n6.20\n3.90\n12.87"
  },
  {
    "objectID": "practice/practice2.html#演练2.8",
    "href": "practice/practice2.html#演练2.8",
    "title": "演练2.1",
    "section": "演练2.8",
    "text": "演练2.8\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :])\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.063782\n30\ntwo-sided\n0.949567\n[-2.0, 1.87]\n0.02255\n0.337\n0.050437\n\n\n\n\n\n\n\n\npg.ttest(x=data_n.iloc[0, :], y=data_p.iloc[0, :], paired=True)\n\n\n\n\n\n\n\n\nT\ndof\nalternative\np-val\nCI95%\ncohen-d\nBF10\npower\n\n\n\n\nT-test\n-0.149959\n15\ntwo-sided\n0.882795\n[-0.92, 0.8]\n0.02255\n0.258\n0.05082"
  },
  {
    "objectID": "practice/pratice3_2.html",
    "href": "practice/pratice3_2.html",
    "title": "",
    "section": "",
    "text": "from bs4 import BeautifulSoup\nimport requests\nimport re\nimport pandas as pd\n\n\n# Downloading imdb top 250 movie's data\nurl = 'http://www.imdb.com/chart/top'\nheaders = {\n    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\"\n}\nresponse = requests.get(url,headers=headers)\nsoup = BeautifulSoup(response.text, \"html.parser\")\nmovies = soup.find_all('div',class_=\"sc-300a8231-0 gTnHyA cli-children\")\nratings = soup.find_all(\"span\",class_=\"ipc-rating-star--rating\")\n\n[]\n\n\n\nlist = []\n\nfor index in range(0, len(movies)):\n    \n    movie_string = movies[index].find(\"h3\",class_='ipc-title__text').get_text()\n    movie_title = movie_string.split(\".\")[1]\n    place = movie_string.split(\".\")[0]\n    year = movies[index].find(\"span\",class_='sc-300a8231-7 eaXxft cli-title-metadata-item').get_text()\n    \n    data = {\"place\": place,\n            \"movie_title\": movie_title,\n            \"rating\": ratings[index].get_text(),\n            \"year\": year,\n            }\n    list.append(data)\nfor movie in list:\n    print(movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n        ') -', 'Starring:', movie['rating'])\n#saving the list as dataframe\n#then converting into .csv file\ndf = pd.DataFrame(list)\ndf.to_csv('imdb_top_250_movies.csv',index=False)\n\n1 -  The Shawshank Redemption (1994) - Starring: 9.3\n2 -  The Godfather (1972) - Starring: 9.2\n3 -  The Dark Knight (2008) - Starring: 9.0\n4 -  The Godfather Part II (1974) - Starring: 9.0\n5 -  12 Angry Men (1957) - Starring: 9.0\n6 -  The Lord of the Rings: The Return of the King (2003) - Starring: 9.0\n7 -  Schindler's List (1993) - Starring: 9.0\n8 -  Pulp Fiction (1994) - Starring: 8.9\n9 -  The Lord of the Rings: The Fellowship of the Ring (2001) - Starring: 8.9\n10 -  Il buono, il brutto, il cattivo (1966) - Starring: 8.8\n11 -  Forrest Gump (1994) - Starring: 8.8\n12 -  The Lord of the Rings: The Two Towers (2002) - Starring: 8.8\n13 -  Fight Club (1999) - Starring: 8.8\n14 -  Inception (2010) - Starring: 8.8\n15 -  Star Wars: Episode V - The Empire Strikes Back (1980) - Starring: 8.7\n16 -  The Matrix (1999) - Starring: 8.7\n17 -  Goodfellas (1990) - Starring: 8.7\n18 -  One Flew Over the Cuckoo's Nest (1975) - Starring: 8.7\n19 -  Interstellar (2014) - Starring: 8.7\n20 -  Se7en (1995) - Starring: 8.6\n21 -  It's a Wonderful Life (1946) - Starring: 8.6\n22 -  Shichinin no samurai (1954) - Starring: 8.6\n23 -  The Silence of the Lambs (1991) - Starring: 8.6\n24 -  Saving Private Ryan (1998) - Starring: 8.6\n25 -  Cidade de Deus (2002) - Starring: 8.6"
  },
  {
    "objectID": "practice/pratice4.html",
    "href": "practice/pratice4.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# 读取数据\ndouban_file_path = 'douban_top250.csv'\nimdb_file_path = 'imdb_top_250_movies.csv'\n\n\ndouban_data = pd.read_csv(douban_file_path)\nimdb_data = pd.read_csv(imdb_file_path)\n\n#1. 平台平均评分比较\ndouban_avg_rating = douban_data['rating'].mean()\nimdb_avg_rating = imdb_data['rating'].mean()\n\n# 可视化平均评分比较\nplatforms = ['Douban', 'IMDb']\nratings = [douban_avg_rating, imdb_avg_rating]\n\nplt.figure(figsize=(8, 6))\nplt.bar(platforms, ratings, color=['skyblue', 'coral'])\nplt.title('Average Ratings: Douban vs IMDb')\nplt.ylabel('Average Rating')\nplt.show()\n\n# 创建中英文标题映射\ntitle_mapping = {\n    '肖申克的救赎': 'The Shawshank Redemption',\n    '阿甘正传': 'Forrest Gump',\n    '泰坦尼克号': 'Titanic',\n    '千与千寻': 'Spirited Away',\n    '美丽人生': 'Life Is Beautiful',\n    '这个杀手不太冷': 'Leon: The Professional',\n    '星际穿越': 'Interstellar',\n    '盗梦空间': 'Inception',\n    '辛德勒的名单': \"Schindler's List\",\n    '无间道': \"Infernal Affairs\",\n    '三傻大闹宝莱坞': \"3 Idiots\"\n}\n\n\n\n\n\n\n\n\n\n\ndouban_data['mapped_title'] = douban_data['title'].map(title_mapping)\noverlap_movies = pd.merge(douban_data, imdb_data, left_on='mapped_title', right_on='movie_title', how='inner')\n\nprint(\"Movies appearing on both platforms:\")\nprint(overlap_movies[['title', 'rating_x', 'rating_y', 'year']])\n\n# 上映年份分布 \nplt.figure(figsize=(10, 6))\nplt.hist(imdb_data['year'], bins=20, color='coral', alpha=0.7, edgecolor='black')\nplt.title('Distribution of Movie Release Years (IMDb)')\nplt.xlabel('Year')\nplt.ylabel('Number of Movies')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n# 4. 类型分布\nif 'genre' in imdb_data.columns:\n    # 拆分类型列并统计分布\n    genre_series = imdb_data['genre'].str.split(',').explode()\n    genre_counts = genre_series.value_counts().head(10)  # 显示Top 10类型\n\n    plt.figure(figsize=(10, 6))\n    genre_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n    plt.title('Top 10 Movie Genres (IMDb)')\n    plt.xlabel('Genre')\n    plt.ylabel('Count')\n    plt.xticks(rotation=45)\n    plt.show()\n\nMovies appearing on both platforms:\nEmpty DataFrame\nColumns: [title, rating_x, rating_y, year]\nIndex: []"
  }
]